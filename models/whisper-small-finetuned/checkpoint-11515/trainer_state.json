{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.9999565802613868,
  "eval_steps": 500,
  "global_step": 11515,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.004341973861317355,
      "grad_norm": 32.08115005493164,
      "learning_rate": 9.98697351280938e-06,
      "loss": 2.7201,
      "step": 50
    },
    {
      "epoch": 0.00868394772263471,
      "grad_norm": 11.602313041687012,
      "learning_rate": 9.972499638153135e-06,
      "loss": 0.8616,
      "step": 100
    },
    {
      "epoch": 0.013025921583952065,
      "grad_norm": 13.351936340332031,
      "learning_rate": 9.95802576349689e-06,
      "loss": 0.3809,
      "step": 150
    },
    {
      "epoch": 0.01736789544526942,
      "grad_norm": 11.841660499572754,
      "learning_rate": 9.943551888840644e-06,
      "loss": 0.3299,
      "step": 200
    },
    {
      "epoch": 0.021709869306586773,
      "grad_norm": 13.042312622070312,
      "learning_rate": 9.929078014184398e-06,
      "loss": 0.3422,
      "step": 250
    },
    {
      "epoch": 0.02605184316790413,
      "grad_norm": 12.432320594787598,
      "learning_rate": 9.914604139528152e-06,
      "loss": 0.3427,
      "step": 300
    },
    {
      "epoch": 0.030393817029221483,
      "grad_norm": 11.445119857788086,
      "learning_rate": 9.900130264871906e-06,
      "loss": 0.3318,
      "step": 350
    },
    {
      "epoch": 0.03473579089053884,
      "grad_norm": 16.4143009185791,
      "learning_rate": 9.885656390215662e-06,
      "loss": 0.2945,
      "step": 400
    },
    {
      "epoch": 0.039077764751856196,
      "grad_norm": 10.369935989379883,
      "learning_rate": 9.871182515559416e-06,
      "loss": 0.3232,
      "step": 450
    },
    {
      "epoch": 0.043419738613173546,
      "grad_norm": 10.7285737991333,
      "learning_rate": 9.856708640903172e-06,
      "loss": 0.3065,
      "step": 500
    },
    {
      "epoch": 0.0477617124744909,
      "grad_norm": 9.987811088562012,
      "learning_rate": 9.842234766246926e-06,
      "loss": 0.2889,
      "step": 550
    },
    {
      "epoch": 0.05210368633580826,
      "grad_norm": 13.18855094909668,
      "learning_rate": 9.82776089159068e-06,
      "loss": 0.359,
      "step": 600
    },
    {
      "epoch": 0.056445660197125616,
      "grad_norm": 7.523106098175049,
      "learning_rate": 9.813287016934434e-06,
      "loss": 0.3753,
      "step": 650
    },
    {
      "epoch": 0.060787634058442966,
      "grad_norm": 8.611462593078613,
      "learning_rate": 9.798813142278188e-06,
      "loss": 0.327,
      "step": 700
    },
    {
      "epoch": 0.06512960791976033,
      "grad_norm": 9.731183052062988,
      "learning_rate": 9.784339267621942e-06,
      "loss": 0.3218,
      "step": 750
    },
    {
      "epoch": 0.06947158178107768,
      "grad_norm": 14.622904777526855,
      "learning_rate": 9.769865392965696e-06,
      "loss": 0.3116,
      "step": 800
    },
    {
      "epoch": 0.07381355564239503,
      "grad_norm": 14.486369132995605,
      "learning_rate": 9.755391518309452e-06,
      "loss": 0.302,
      "step": 850
    },
    {
      "epoch": 0.07815552950371239,
      "grad_norm": 9.997029304504395,
      "learning_rate": 9.740917643653206e-06,
      "loss": 0.3332,
      "step": 900
    },
    {
      "epoch": 0.08249750336502974,
      "grad_norm": 11.677199363708496,
      "learning_rate": 9.726443768996962e-06,
      "loss": 0.2776,
      "step": 950
    },
    {
      "epoch": 0.08683947722634709,
      "grad_norm": 15.453819274902344,
      "learning_rate": 9.711969894340716e-06,
      "loss": 0.304,
      "step": 1000
    },
    {
      "epoch": 0.09118145108766446,
      "grad_norm": 10.257116317749023,
      "learning_rate": 9.69749601968447e-06,
      "loss": 0.3241,
      "step": 1050
    },
    {
      "epoch": 0.0955234249489818,
      "grad_norm": 12.801012992858887,
      "learning_rate": 9.683022145028224e-06,
      "loss": 0.3245,
      "step": 1100
    },
    {
      "epoch": 0.09986539881029916,
      "grad_norm": 9.938461303710938,
      "learning_rate": 9.668548270371979e-06,
      "loss": 0.3146,
      "step": 1150
    },
    {
      "epoch": 0.10420737267161652,
      "grad_norm": 7.490509986877441,
      "learning_rate": 9.654074395715733e-06,
      "loss": 0.2823,
      "step": 1200
    },
    {
      "epoch": 0.10854934653293387,
      "grad_norm": 13.965841293334961,
      "learning_rate": 9.639600521059488e-06,
      "loss": 0.3684,
      "step": 1250
    },
    {
      "epoch": 0.11289132039425123,
      "grad_norm": 12.257745742797852,
      "learning_rate": 9.625126646403243e-06,
      "loss": 0.3316,
      "step": 1300
    },
    {
      "epoch": 0.11723329425556858,
      "grad_norm": 13.204375267028809,
      "learning_rate": 9.610652771746998e-06,
      "loss": 0.2866,
      "step": 1350
    },
    {
      "epoch": 0.12157526811688593,
      "grad_norm": 14.752259254455566,
      "learning_rate": 9.596178897090753e-06,
      "loss": 0.2965,
      "step": 1400
    },
    {
      "epoch": 0.12591724197820328,
      "grad_norm": 14.065028190612793,
      "learning_rate": 9.581705022434507e-06,
      "loss": 0.2953,
      "step": 1450
    },
    {
      "epoch": 0.13025921583952066,
      "grad_norm": 7.947408676147461,
      "learning_rate": 9.56723114777826e-06,
      "loss": 0.3143,
      "step": 1500
    },
    {
      "epoch": 0.134601189700838,
      "grad_norm": 14.14394474029541,
      "learning_rate": 9.552757273122015e-06,
      "loss": 0.2843,
      "step": 1550
    },
    {
      "epoch": 0.13894316356215536,
      "grad_norm": 8.776320457458496,
      "learning_rate": 9.538283398465769e-06,
      "loss": 0.2435,
      "step": 1600
    },
    {
      "epoch": 0.1432851374234727,
      "grad_norm": 8.089349746704102,
      "learning_rate": 9.523809523809525e-06,
      "loss": 0.3011,
      "step": 1650
    },
    {
      "epoch": 0.14762711128479006,
      "grad_norm": 9.590496063232422,
      "learning_rate": 9.509335649153279e-06,
      "loss": 0.2947,
      "step": 1700
    },
    {
      "epoch": 0.1519690851461074,
      "grad_norm": 9.659972190856934,
      "learning_rate": 9.494861774497035e-06,
      "loss": 0.3485,
      "step": 1750
    },
    {
      "epoch": 0.15631105900742479,
      "grad_norm": 10.331656455993652,
      "learning_rate": 9.480387899840789e-06,
      "loss": 0.2765,
      "step": 1800
    },
    {
      "epoch": 0.16065303286874213,
      "grad_norm": 12.779083251953125,
      "learning_rate": 9.465914025184543e-06,
      "loss": 0.2817,
      "step": 1850
    },
    {
      "epoch": 0.16499500673005948,
      "grad_norm": 9.097893714904785,
      "learning_rate": 9.451440150528297e-06,
      "loss": 0.3581,
      "step": 1900
    },
    {
      "epoch": 0.16933698059137683,
      "grad_norm": 18.47726058959961,
      "learning_rate": 9.436966275872051e-06,
      "loss": 0.2617,
      "step": 1950
    },
    {
      "epoch": 0.17367895445269418,
      "grad_norm": 7.92081356048584,
      "learning_rate": 9.422492401215805e-06,
      "loss": 0.3314,
      "step": 2000
    },
    {
      "epoch": 0.17802092831401156,
      "grad_norm": 11.863414764404297,
      "learning_rate": 9.408018526559561e-06,
      "loss": 0.3495,
      "step": 2050
    },
    {
      "epoch": 0.1823629021753289,
      "grad_norm": 12.667139053344727,
      "learning_rate": 9.393544651903315e-06,
      "loss": 0.318,
      "step": 2100
    },
    {
      "epoch": 0.18670487603664626,
      "grad_norm": 13.5122652053833,
      "learning_rate": 9.379070777247071e-06,
      "loss": 0.3017,
      "step": 2150
    },
    {
      "epoch": 0.1910468498979636,
      "grad_norm": 6.8720526695251465,
      "learning_rate": 9.364596902590825e-06,
      "loss": 0.2728,
      "step": 2200
    },
    {
      "epoch": 0.19538882375928096,
      "grad_norm": 15.49057388305664,
      "learning_rate": 9.350123027934579e-06,
      "loss": 0.2858,
      "step": 2250
    },
    {
      "epoch": 0.1997307976205983,
      "grad_norm": 13.840463638305664,
      "learning_rate": 9.335649153278333e-06,
      "loss": 0.2733,
      "step": 2300
    },
    {
      "epoch": 0.2040727714819157,
      "grad_norm": 12.819256782531738,
      "learning_rate": 9.321175278622087e-06,
      "loss": 0.3099,
      "step": 2350
    },
    {
      "epoch": 0.20841474534323304,
      "grad_norm": 14.073617935180664,
      "learning_rate": 9.306701403965841e-06,
      "loss": 0.3347,
      "step": 2400
    },
    {
      "epoch": 0.2127567192045504,
      "grad_norm": 9.651225090026855,
      "learning_rate": 9.292227529309597e-06,
      "loss": 0.3033,
      "step": 2450
    },
    {
      "epoch": 0.21709869306586774,
      "grad_norm": 8.687524795532227,
      "learning_rate": 9.277753654653351e-06,
      "loss": 0.2807,
      "step": 2500
    },
    {
      "epoch": 0.2214406669271851,
      "grad_norm": 10.235136032104492,
      "learning_rate": 9.263279779997107e-06,
      "loss": 0.2196,
      "step": 2550
    },
    {
      "epoch": 0.22578264078850246,
      "grad_norm": 12.453109741210938,
      "learning_rate": 9.248805905340861e-06,
      "loss": 0.336,
      "step": 2600
    },
    {
      "epoch": 0.23012461464981981,
      "grad_norm": 11.39977741241455,
      "learning_rate": 9.234332030684615e-06,
      "loss": 0.287,
      "step": 2650
    },
    {
      "epoch": 0.23446658851113716,
      "grad_norm": 15.636773109436035,
      "learning_rate": 9.21985815602837e-06,
      "loss": 0.2747,
      "step": 2700
    },
    {
      "epoch": 0.2388085623724545,
      "grad_norm": 9.498825073242188,
      "learning_rate": 9.205384281372124e-06,
      "loss": 0.2462,
      "step": 2750
    },
    {
      "epoch": 0.24315053623377186,
      "grad_norm": 3.69565486907959,
      "learning_rate": 9.190910406715878e-06,
      "loss": 0.2816,
      "step": 2800
    },
    {
      "epoch": 0.24749251009508924,
      "grad_norm": 12.666276931762695,
      "learning_rate": 9.176436532059632e-06,
      "loss": 0.3002,
      "step": 2850
    },
    {
      "epoch": 0.25183448395640656,
      "grad_norm": 16.72841453552246,
      "learning_rate": 9.161962657403388e-06,
      "loss": 0.2584,
      "step": 2900
    },
    {
      "epoch": 0.2561764578177239,
      "grad_norm": 11.932791709899902,
      "learning_rate": 9.147488782747142e-06,
      "loss": 0.311,
      "step": 2950
    },
    {
      "epoch": 0.2605184316790413,
      "grad_norm": 7.06049919128418,
      "learning_rate": 9.133014908090898e-06,
      "loss": 0.2333,
      "step": 3000
    },
    {
      "epoch": 0.26486040554035867,
      "grad_norm": 13.139076232910156,
      "learning_rate": 9.118541033434652e-06,
      "loss": 0.2429,
      "step": 3050
    },
    {
      "epoch": 0.269202379401676,
      "grad_norm": 4.549722671508789,
      "learning_rate": 9.104067158778406e-06,
      "loss": 0.2384,
      "step": 3100
    },
    {
      "epoch": 0.27354435326299337,
      "grad_norm": 15.118318557739258,
      "learning_rate": 9.08959328412216e-06,
      "loss": 0.3034,
      "step": 3150
    },
    {
      "epoch": 0.2778863271243107,
      "grad_norm": 11.380433082580566,
      "learning_rate": 9.075119409465914e-06,
      "loss": 0.2701,
      "step": 3200
    },
    {
      "epoch": 0.28222830098562807,
      "grad_norm": 8.537070274353027,
      "learning_rate": 9.060645534809668e-06,
      "loss": 0.2854,
      "step": 3250
    },
    {
      "epoch": 0.2865702748469454,
      "grad_norm": 15.4993314743042,
      "learning_rate": 9.046171660153424e-06,
      "loss": 0.3197,
      "step": 3300
    },
    {
      "epoch": 0.29091224870826277,
      "grad_norm": 39.80760192871094,
      "learning_rate": 9.031697785497178e-06,
      "loss": 0.3389,
      "step": 3350
    },
    {
      "epoch": 0.2952542225695801,
      "grad_norm": 11.710318565368652,
      "learning_rate": 9.017223910840934e-06,
      "loss": 0.2886,
      "step": 3400
    },
    {
      "epoch": 0.29959619643089747,
      "grad_norm": 10.475316047668457,
      "learning_rate": 9.002750036184688e-06,
      "loss": 0.285,
      "step": 3450
    },
    {
      "epoch": 0.3039381702922148,
      "grad_norm": 7.522524833679199,
      "learning_rate": 8.988276161528442e-06,
      "loss": 0.298,
      "step": 3500
    },
    {
      "epoch": 0.3082801441535322,
      "grad_norm": 5.4467244148254395,
      "learning_rate": 8.973802286872196e-06,
      "loss": 0.2792,
      "step": 3550
    },
    {
      "epoch": 0.31262211801484957,
      "grad_norm": 12.941061973571777,
      "learning_rate": 8.95932841221595e-06,
      "loss": 0.2212,
      "step": 3600
    },
    {
      "epoch": 0.3169640918761669,
      "grad_norm": 13.501566886901855,
      "learning_rate": 8.944854537559704e-06,
      "loss": 0.2792,
      "step": 3650
    },
    {
      "epoch": 0.32130606573748427,
      "grad_norm": 5.546044826507568,
      "learning_rate": 8.93038066290346e-06,
      "loss": 0.3064,
      "step": 3700
    },
    {
      "epoch": 0.3256480395988016,
      "grad_norm": 9.782098770141602,
      "learning_rate": 8.915906788247214e-06,
      "loss": 0.2601,
      "step": 3750
    },
    {
      "epoch": 0.32999001346011897,
      "grad_norm": 4.493556022644043,
      "learning_rate": 8.90143291359097e-06,
      "loss": 0.2417,
      "step": 3800
    },
    {
      "epoch": 0.3343319873214363,
      "grad_norm": 10.674678802490234,
      "learning_rate": 8.886959038934724e-06,
      "loss": 0.2525,
      "step": 3850
    },
    {
      "epoch": 0.33867396118275367,
      "grad_norm": 12.951682090759277,
      "learning_rate": 8.872485164278478e-06,
      "loss": 0.2882,
      "step": 3900
    },
    {
      "epoch": 0.343015935044071,
      "grad_norm": 15.413273811340332,
      "learning_rate": 8.858011289622232e-06,
      "loss": 0.268,
      "step": 3950
    },
    {
      "epoch": 0.34735790890538837,
      "grad_norm": 6.657174110412598,
      "learning_rate": 8.843537414965987e-06,
      "loss": 0.2952,
      "step": 4000
    },
    {
      "epoch": 0.3516998827667057,
      "grad_norm": 6.247474670410156,
      "learning_rate": 8.82906354030974e-06,
      "loss": 0.2185,
      "step": 4050
    },
    {
      "epoch": 0.3560418566280231,
      "grad_norm": 14.013585090637207,
      "learning_rate": 8.814589665653496e-06,
      "loss": 0.2911,
      "step": 4100
    },
    {
      "epoch": 0.3603838304893405,
      "grad_norm": 4.614453315734863,
      "learning_rate": 8.80011579099725e-06,
      "loss": 0.2627,
      "step": 4150
    },
    {
      "epoch": 0.3647258043506578,
      "grad_norm": 18.471010208129883,
      "learning_rate": 8.785641916341006e-06,
      "loss": 0.2986,
      "step": 4200
    },
    {
      "epoch": 0.3690677782119752,
      "grad_norm": 20.08515167236328,
      "learning_rate": 8.771457519177886e-06,
      "loss": 0.2659,
      "step": 4250
    },
    {
      "epoch": 0.3734097520732925,
      "grad_norm": 11.523843765258789,
      "learning_rate": 8.75698364452164e-06,
      "loss": 0.2879,
      "step": 4300
    },
    {
      "epoch": 0.37775172593460987,
      "grad_norm": 12.521258354187012,
      "learning_rate": 8.742509769865394e-06,
      "loss": 0.2479,
      "step": 4350
    },
    {
      "epoch": 0.3820936997959272,
      "grad_norm": 4.8445587158203125,
      "learning_rate": 8.728035895209148e-06,
      "loss": 0.3093,
      "step": 4400
    },
    {
      "epoch": 0.38643567365724457,
      "grad_norm": 16.926706314086914,
      "learning_rate": 8.713562020552902e-06,
      "loss": 0.2764,
      "step": 4450
    },
    {
      "epoch": 0.3907776475185619,
      "grad_norm": 12.894941329956055,
      "learning_rate": 8.699088145896656e-06,
      "loss": 0.326,
      "step": 4500
    },
    {
      "epoch": 0.39511962137987927,
      "grad_norm": 7.567624568939209,
      "learning_rate": 8.684614271240412e-06,
      "loss": 0.2442,
      "step": 4550
    },
    {
      "epoch": 0.3994615952411966,
      "grad_norm": 0.5340330600738525,
      "learning_rate": 8.670140396584166e-06,
      "loss": 0.2505,
      "step": 4600
    },
    {
      "epoch": 0.403803569102514,
      "grad_norm": 2.206448554992676,
      "learning_rate": 8.655666521927922e-06,
      "loss": 0.2872,
      "step": 4650
    },
    {
      "epoch": 0.4081455429638314,
      "grad_norm": 3.9290964603424072,
      "learning_rate": 8.641192647271676e-06,
      "loss": 0.264,
      "step": 4700
    },
    {
      "epoch": 0.4124875168251487,
      "grad_norm": 10.728494644165039,
      "learning_rate": 8.62671877261543e-06,
      "loss": 0.3088,
      "step": 4750
    },
    {
      "epoch": 0.4168294906864661,
      "grad_norm": 1.5482255220413208,
      "learning_rate": 8.612244897959184e-06,
      "loss": 0.2577,
      "step": 4800
    },
    {
      "epoch": 0.4211714645477834,
      "grad_norm": 12.54301929473877,
      "learning_rate": 8.597771023302938e-06,
      "loss": 0.2649,
      "step": 4850
    },
    {
      "epoch": 0.4255134384091008,
      "grad_norm": 8.942083358764648,
      "learning_rate": 8.583297148646693e-06,
      "loss": 0.3254,
      "step": 4900
    },
    {
      "epoch": 0.4298554122704181,
      "grad_norm": 6.604653358459473,
      "learning_rate": 8.568823273990448e-06,
      "loss": 0.3005,
      "step": 4950
    },
    {
      "epoch": 0.4341973861317355,
      "grad_norm": 4.268127918243408,
      "learning_rate": 8.554349399334202e-06,
      "loss": 0.2745,
      "step": 5000
    },
    {
      "epoch": 0.4385393599930528,
      "grad_norm": 6.471729755401611,
      "learning_rate": 8.539875524677957e-06,
      "loss": 0.2735,
      "step": 5050
    },
    {
      "epoch": 0.4428813338543702,
      "grad_norm": 15.852076530456543,
      "learning_rate": 8.525401650021712e-06,
      "loss": 0.3188,
      "step": 5100
    },
    {
      "epoch": 0.4472233077156876,
      "grad_norm": 9.784584999084473,
      "learning_rate": 8.510927775365467e-06,
      "loss": 0.2664,
      "step": 5150
    },
    {
      "epoch": 0.45156528157700493,
      "grad_norm": 7.76936674118042,
      "learning_rate": 8.49645390070922e-06,
      "loss": 0.2571,
      "step": 5200
    },
    {
      "epoch": 0.4559072554383223,
      "grad_norm": 11.905091285705566,
      "learning_rate": 8.481980026052975e-06,
      "loss": 0.3088,
      "step": 5250
    },
    {
      "epoch": 0.46024922929963963,
      "grad_norm": 7.778932094573975,
      "learning_rate": 8.467506151396729e-06,
      "loss": 0.2754,
      "step": 5300
    },
    {
      "epoch": 0.464591203160957,
      "grad_norm": 7.64968729019165,
      "learning_rate": 8.453032276740483e-06,
      "loss": 0.253,
      "step": 5350
    },
    {
      "epoch": 0.46893317702227433,
      "grad_norm": 7.020500183105469,
      "learning_rate": 8.438558402084239e-06,
      "loss": 0.2032,
      "step": 5400
    },
    {
      "epoch": 0.4732751508835917,
      "grad_norm": 15.488313674926758,
      "learning_rate": 8.424084527427993e-06,
      "loss": 0.2675,
      "step": 5450
    },
    {
      "epoch": 0.477617124744909,
      "grad_norm": 6.211950302124023,
      "learning_rate": 8.409610652771749e-06,
      "loss": 0.2203,
      "step": 5500
    },
    {
      "epoch": 0.4819590986062264,
      "grad_norm": 11.131321907043457,
      "learning_rate": 8.395136778115503e-06,
      "loss": 0.323,
      "step": 5550
    },
    {
      "epoch": 0.4863010724675437,
      "grad_norm": 7.9977126121521,
      "learning_rate": 8.380662903459257e-06,
      "loss": 0.2231,
      "step": 5600
    },
    {
      "epoch": 0.4906430463288611,
      "grad_norm": 10.198436737060547,
      "learning_rate": 8.366189028803011e-06,
      "loss": 0.2465,
      "step": 5650
    },
    {
      "epoch": 0.4949850201901785,
      "grad_norm": 14.98998737335205,
      "learning_rate": 8.351715154146765e-06,
      "loss": 0.2235,
      "step": 5700
    },
    {
      "epoch": 0.49932699405149583,
      "grad_norm": 13.291168212890625,
      "learning_rate": 8.33724127949052e-06,
      "loss": 0.2082,
      "step": 5750
    },
    {
      "epoch": 0.5036689679128131,
      "grad_norm": 11.353480339050293,
      "learning_rate": 8.322767404834275e-06,
      "loss": 0.2813,
      "step": 5800
    },
    {
      "epoch": 0.5080109417741305,
      "grad_norm": 4.9565815925598145,
      "learning_rate": 8.308293530178029e-06,
      "loss": 0.2223,
      "step": 5850
    },
    {
      "epoch": 0.5123529156354478,
      "grad_norm": 10.184609413146973,
      "learning_rate": 8.293819655521785e-06,
      "loss": 0.2622,
      "step": 5900
    },
    {
      "epoch": 0.5166948894967652,
      "grad_norm": 11.807438850402832,
      "learning_rate": 8.279345780865539e-06,
      "loss": 0.221,
      "step": 5950
    },
    {
      "epoch": 0.5210368633580826,
      "grad_norm": 10.200774192810059,
      "learning_rate": 8.264871906209293e-06,
      "loss": 0.2987,
      "step": 6000
    },
    {
      "epoch": 0.5253788372193999,
      "grad_norm": 12.71509838104248,
      "learning_rate": 8.250398031553047e-06,
      "loss": 0.281,
      "step": 6050
    },
    {
      "epoch": 0.5297208110807173,
      "grad_norm": 6.515493392944336,
      "learning_rate": 8.235924156896801e-06,
      "loss": 0.2731,
      "step": 6100
    },
    {
      "epoch": 0.5340627849420346,
      "grad_norm": 12.207219123840332,
      "learning_rate": 8.221450282240555e-06,
      "loss": 0.1996,
      "step": 6150
    },
    {
      "epoch": 0.538404758803352,
      "grad_norm": 14.700127601623535,
      "learning_rate": 8.206976407584311e-06,
      "loss": 0.2901,
      "step": 6200
    },
    {
      "epoch": 0.5427467326646693,
      "grad_norm": 13.294961929321289,
      "learning_rate": 8.192502532928065e-06,
      "loss": 0.2529,
      "step": 6250
    },
    {
      "epoch": 0.5470887065259867,
      "grad_norm": 7.7809295654296875,
      "learning_rate": 8.178028658271821e-06,
      "loss": 0.2201,
      "step": 6300
    },
    {
      "epoch": 0.551430680387304,
      "grad_norm": 9.105611801147461,
      "learning_rate": 8.163554783615575e-06,
      "loss": 0.2144,
      "step": 6350
    },
    {
      "epoch": 0.5557726542486214,
      "grad_norm": 9.768695831298828,
      "learning_rate": 8.149370386452455e-06,
      "loss": 0.2631,
      "step": 6400
    },
    {
      "epoch": 0.5601146281099387,
      "grad_norm": 15.364813804626465,
      "learning_rate": 8.134896511796209e-06,
      "loss": 0.2801,
      "step": 6450
    },
    {
      "epoch": 0.5644566019712561,
      "grad_norm": 11.26169204711914,
      "learning_rate": 8.120422637139963e-06,
      "loss": 0.2521,
      "step": 6500
    },
    {
      "epoch": 0.5687985758325735,
      "grad_norm": 14.16651725769043,
      "learning_rate": 8.105948762483717e-06,
      "loss": 0.2911,
      "step": 6550
    },
    {
      "epoch": 0.5731405496938908,
      "grad_norm": 7.423428535461426,
      "learning_rate": 8.091474887827471e-06,
      "loss": 0.2962,
      "step": 6600
    },
    {
      "epoch": 0.5774825235552082,
      "grad_norm": 12.954950332641602,
      "learning_rate": 8.077001013171227e-06,
      "loss": 0.2628,
      "step": 6650
    },
    {
      "epoch": 0.5818244974165255,
      "grad_norm": 0.6374977827072144,
      "learning_rate": 8.062527138514981e-06,
      "loss": 0.2317,
      "step": 6700
    },
    {
      "epoch": 0.5861664712778429,
      "grad_norm": 14.547224998474121,
      "learning_rate": 8.048053263858737e-06,
      "loss": 0.2576,
      "step": 6750
    },
    {
      "epoch": 0.5905084451391602,
      "grad_norm": 15.81212043762207,
      "learning_rate": 8.033579389202491e-06,
      "loss": 0.2389,
      "step": 6800
    },
    {
      "epoch": 0.5948504190004776,
      "grad_norm": 6.094769477844238,
      "learning_rate": 8.019105514546245e-06,
      "loss": 0.2705,
      "step": 6850
    },
    {
      "epoch": 0.5991923928617949,
      "grad_norm": 12.700167655944824,
      "learning_rate": 8.00463163989e-06,
      "loss": 0.2271,
      "step": 6900
    },
    {
      "epoch": 0.6035343667231123,
      "grad_norm": 9.446319580078125,
      "learning_rate": 7.990157765233753e-06,
      "loss": 0.1957,
      "step": 6950
    },
    {
      "epoch": 0.6078763405844296,
      "grad_norm": 10.391845703125,
      "learning_rate": 7.975683890577507e-06,
      "loss": 0.2764,
      "step": 7000
    },
    {
      "epoch": 0.612218314445747,
      "grad_norm": 0.8525072932243347,
      "learning_rate": 7.961210015921263e-06,
      "loss": 0.2413,
      "step": 7050
    },
    {
      "epoch": 0.6165602883070644,
      "grad_norm": 13.354928970336914,
      "learning_rate": 7.946736141265017e-06,
      "loss": 0.2644,
      "step": 7100
    },
    {
      "epoch": 0.6209022621683817,
      "grad_norm": 10.913607597351074,
      "learning_rate": 7.932262266608773e-06,
      "loss": 0.2478,
      "step": 7150
    },
    {
      "epoch": 0.6252442360296991,
      "grad_norm": 10.41576099395752,
      "learning_rate": 7.917788391952527e-06,
      "loss": 0.2523,
      "step": 7200
    },
    {
      "epoch": 0.6295862098910164,
      "grad_norm": 9.93879508972168,
      "learning_rate": 7.903314517296281e-06,
      "loss": 0.2313,
      "step": 7250
    },
    {
      "epoch": 0.6339281837523338,
      "grad_norm": 11.395098686218262,
      "learning_rate": 7.888840642640035e-06,
      "loss": 0.2674,
      "step": 7300
    },
    {
      "epoch": 0.6382701576136511,
      "grad_norm": 13.613016128540039,
      "learning_rate": 7.87436676798379e-06,
      "loss": 0.2442,
      "step": 7350
    },
    {
      "epoch": 0.6426121314749685,
      "grad_norm": 7.089151859283447,
      "learning_rate": 7.859892893327544e-06,
      "loss": 0.2313,
      "step": 7400
    },
    {
      "epoch": 0.6469541053362858,
      "grad_norm": 9.300673484802246,
      "learning_rate": 7.845419018671298e-06,
      "loss": 0.2631,
      "step": 7450
    },
    {
      "epoch": 0.6512960791976032,
      "grad_norm": 12.743701934814453,
      "learning_rate": 7.830945144015054e-06,
      "loss": 0.2909,
      "step": 7500
    },
    {
      "epoch": 0.6556380530589205,
      "grad_norm": 7.693624019622803,
      "learning_rate": 7.816471269358808e-06,
      "loss": 0.3017,
      "step": 7550
    },
    {
      "epoch": 0.6599800269202379,
      "grad_norm": 10.756463050842285,
      "learning_rate": 7.801997394702564e-06,
      "loss": 0.2438,
      "step": 7600
    },
    {
      "epoch": 0.6643220007815553,
      "grad_norm": 9.87155818939209,
      "learning_rate": 7.787523520046318e-06,
      "loss": 0.2453,
      "step": 7650
    },
    {
      "epoch": 0.6686639746428726,
      "grad_norm": 4.115950107574463,
      "learning_rate": 7.773049645390072e-06,
      "loss": 0.2131,
      "step": 7700
    },
    {
      "epoch": 0.67300594850419,
      "grad_norm": 0.4190388023853302,
      "learning_rate": 7.758575770733826e-06,
      "loss": 0.2383,
      "step": 7750
    },
    {
      "epoch": 0.6773479223655073,
      "grad_norm": 10.512711524963379,
      "learning_rate": 7.74410189607758e-06,
      "loss": 0.2181,
      "step": 7800
    },
    {
      "epoch": 0.6816898962268247,
      "grad_norm": 9.304518699645996,
      "learning_rate": 7.729628021421334e-06,
      "loss": 0.2388,
      "step": 7850
    },
    {
      "epoch": 0.686031870088142,
      "grad_norm": 6.525651931762695,
      "learning_rate": 7.71515414676509e-06,
      "loss": 0.2645,
      "step": 7900
    },
    {
      "epoch": 0.6903738439494594,
      "grad_norm": 9.819262504577637,
      "learning_rate": 7.700680272108844e-06,
      "loss": 0.247,
      "step": 7950
    },
    {
      "epoch": 0.6947158178107767,
      "grad_norm": 14.438730239868164,
      "learning_rate": 7.6862063974526e-06,
      "loss": 0.2389,
      "step": 8000
    },
    {
      "epoch": 0.6990577916720941,
      "grad_norm": 12.934776306152344,
      "learning_rate": 7.671732522796354e-06,
      "loss": 0.2695,
      "step": 8050
    },
    {
      "epoch": 0.7033997655334114,
      "grad_norm": 10.648255348205566,
      "learning_rate": 7.657258648140108e-06,
      "loss": 0.2091,
      "step": 8100
    },
    {
      "epoch": 0.7077417393947288,
      "grad_norm": 7.91797399520874,
      "learning_rate": 7.642784773483862e-06,
      "loss": 0.2358,
      "step": 8150
    },
    {
      "epoch": 0.7120837132560462,
      "grad_norm": 8.622334480285645,
      "learning_rate": 7.628310898827617e-06,
      "loss": 0.2107,
      "step": 8200
    },
    {
      "epoch": 0.7164256871173635,
      "grad_norm": 10.815421104431152,
      "learning_rate": 7.613837024171371e-06,
      "loss": 0.2201,
      "step": 8250
    },
    {
      "epoch": 0.720767660978681,
      "grad_norm": 12.649157524108887,
      "learning_rate": 7.599363149515125e-06,
      "loss": 0.258,
      "step": 8300
    },
    {
      "epoch": 0.7251096348399982,
      "grad_norm": 13.133886337280273,
      "learning_rate": 7.58488927485888e-06,
      "loss": 0.2818,
      "step": 8350
    },
    {
      "epoch": 0.7294516087013156,
      "grad_norm": 11.359635353088379,
      "learning_rate": 7.570415400202635e-06,
      "loss": 0.2722,
      "step": 8400
    },
    {
      "epoch": 0.7337935825626329,
      "grad_norm": 17.86835479736328,
      "learning_rate": 7.555941525546389e-06,
      "loss": 0.2276,
      "step": 8450
    },
    {
      "epoch": 0.7381355564239503,
      "grad_norm": 20.632299423217773,
      "learning_rate": 7.541467650890144e-06,
      "loss": 0.291,
      "step": 8500
    },
    {
      "epoch": 0.7424775302852676,
      "grad_norm": 8.320937156677246,
      "learning_rate": 7.526993776233898e-06,
      "loss": 0.2789,
      "step": 8550
    },
    {
      "epoch": 0.746819504146585,
      "grad_norm": 10.321586608886719,
      "learning_rate": 7.5125199015776525e-06,
      "loss": 0.2535,
      "step": 8600
    },
    {
      "epoch": 0.7511614780079023,
      "grad_norm": 3.8393821716308594,
      "learning_rate": 7.4980460269214074e-06,
      "loss": 0.2108,
      "step": 8650
    },
    {
      "epoch": 0.7555034518692197,
      "grad_norm": 8.907423973083496,
      "learning_rate": 7.4835721522651616e-06,
      "loss": 0.2765,
      "step": 8700
    },
    {
      "epoch": 0.7598454257305371,
      "grad_norm": 3.0093770027160645,
      "learning_rate": 7.469098277608916e-06,
      "loss": 0.2116,
      "step": 8750
    },
    {
      "epoch": 0.7641873995918544,
      "grad_norm": 2.4784209728240967,
      "learning_rate": 7.4546244029526715e-06,
      "loss": 0.2738,
      "step": 8800
    },
    {
      "epoch": 0.7685293734531718,
      "grad_norm": 4.4596686363220215,
      "learning_rate": 7.440150528296426e-06,
      "loss": 0.2195,
      "step": 8850
    },
    {
      "epoch": 0.7728713473144891,
      "grad_norm": 3.5557031631469727,
      "learning_rate": 7.4256766536401805e-06,
      "loss": 0.2738,
      "step": 8900
    },
    {
      "epoch": 0.7772133211758065,
      "grad_norm": 10.603437423706055,
      "learning_rate": 7.411202778983935e-06,
      "loss": 0.2311,
      "step": 8950
    },
    {
      "epoch": 0.7815552950371238,
      "grad_norm": 14.556783676147461,
      "learning_rate": 7.396728904327689e-06,
      "loss": 0.2405,
      "step": 9000
    },
    {
      "epoch": 0.7858972688984412,
      "grad_norm": 10.350156784057617,
      "learning_rate": 7.382255029671444e-06,
      "loss": 0.2749,
      "step": 9050
    },
    {
      "epoch": 0.7902392427597585,
      "grad_norm": 8.201991081237793,
      "learning_rate": 7.367781155015198e-06,
      "loss": 0.2591,
      "step": 9100
    },
    {
      "epoch": 0.794581216621076,
      "grad_norm": 2.724789619445801,
      "learning_rate": 7.353307280358952e-06,
      "loss": 0.2934,
      "step": 9150
    },
    {
      "epoch": 0.7989231904823932,
      "grad_norm": 5.613165855407715,
      "learning_rate": 7.338833405702708e-06,
      "loss": 0.2337,
      "step": 9200
    },
    {
      "epoch": 0.8032651643437106,
      "grad_norm": 3.3908209800720215,
      "learning_rate": 7.324359531046462e-06,
      "loss": 0.2413,
      "step": 9250
    },
    {
      "epoch": 0.807607138205028,
      "grad_norm": 9.619438171386719,
      "learning_rate": 7.309885656390217e-06,
      "loss": 0.2663,
      "step": 9300
    },
    {
      "epoch": 0.8119491120663453,
      "grad_norm": 6.928030967712402,
      "learning_rate": 7.295411781733971e-06,
      "loss": 0.2713,
      "step": 9350
    },
    {
      "epoch": 0.8162910859276628,
      "grad_norm": 11.707024574279785,
      "learning_rate": 7.280937907077725e-06,
      "loss": 0.2465,
      "step": 9400
    },
    {
      "epoch": 0.82063305978898,
      "grad_norm": 9.797958374023438,
      "learning_rate": 7.26646403242148e-06,
      "loss": 0.2931,
      "step": 9450
    },
    {
      "epoch": 0.8249750336502975,
      "grad_norm": 11.354745864868164,
      "learning_rate": 7.251990157765234e-06,
      "loss": 0.1794,
      "step": 9500
    },
    {
      "epoch": 0.8293170075116147,
      "grad_norm": 13.923330307006836,
      "learning_rate": 7.237516283108988e-06,
      "loss": 0.2276,
      "step": 9550
    },
    {
      "epoch": 0.8336589813729322,
      "grad_norm": 6.454158306121826,
      "learning_rate": 7.223042408452743e-06,
      "loss": 0.2378,
      "step": 9600
    },
    {
      "epoch": 0.8380009552342494,
      "grad_norm": 6.767538547515869,
      "learning_rate": 7.208568533796498e-06,
      "loss": 0.2194,
      "step": 9650
    },
    {
      "epoch": 0.8423429290955669,
      "grad_norm": 4.610179424285889,
      "learning_rate": 7.194094659140253e-06,
      "loss": 0.1802,
      "step": 9700
    },
    {
      "epoch": 0.8466849029568841,
      "grad_norm": 6.4949870109558105,
      "learning_rate": 7.179620784484007e-06,
      "loss": 0.2525,
      "step": 9750
    },
    {
      "epoch": 0.8510268768182015,
      "grad_norm": 6.070311069488525,
      "learning_rate": 7.165146909827761e-06,
      "loss": 0.2412,
      "step": 9800
    },
    {
      "epoch": 0.855368850679519,
      "grad_norm": 11.405903816223145,
      "learning_rate": 7.150673035171516e-06,
      "loss": 0.2727,
      "step": 9850
    },
    {
      "epoch": 0.8597108245408362,
      "grad_norm": 13.383929252624512,
      "learning_rate": 7.13619916051527e-06,
      "loss": 0.2882,
      "step": 9900
    },
    {
      "epoch": 0.8640527984021537,
      "grad_norm": 13.404510498046875,
      "learning_rate": 7.1217252858590245e-06,
      "loss": 0.2219,
      "step": 9950
    },
    {
      "epoch": 0.868394772263471,
      "grad_norm": 9.866695404052734,
      "learning_rate": 7.107251411202779e-06,
      "loss": 0.2302,
      "step": 10000
    },
    {
      "epoch": 0.8727367461247884,
      "grad_norm": 13.462258338928223,
      "learning_rate": 7.092777536546534e-06,
      "loss": 0.244,
      "step": 10050
    },
    {
      "epoch": 0.8770787199861056,
      "grad_norm": 4.718477249145508,
      "learning_rate": 7.078303661890289e-06,
      "loss": 0.2321,
      "step": 10100
    },
    {
      "epoch": 0.881420693847423,
      "grad_norm": 6.899251937866211,
      "learning_rate": 7.0638297872340434e-06,
      "loss": 0.2126,
      "step": 10150
    },
    {
      "epoch": 0.8857626677087403,
      "grad_norm": 7.1671576499938965,
      "learning_rate": 7.0493559125777976e-06,
      "loss": 0.2159,
      "step": 10200
    },
    {
      "epoch": 0.8901046415700578,
      "grad_norm": 13.115740776062012,
      "learning_rate": 7.0348820379215525e-06,
      "loss": 0.244,
      "step": 10250
    },
    {
      "epoch": 0.8944466154313752,
      "grad_norm": 12.494568824768066,
      "learning_rate": 7.020408163265307e-06,
      "loss": 0.2641,
      "step": 10300
    },
    {
      "epoch": 0.8987885892926925,
      "grad_norm": 9.132339477539062,
      "learning_rate": 7.005934288609061e-06,
      "loss": 0.2483,
      "step": 10350
    },
    {
      "epoch": 0.9031305631540099,
      "grad_norm": 8.740550994873047,
      "learning_rate": 6.991460413952816e-06,
      "loss": 0.1968,
      "step": 10400
    },
    {
      "epoch": 0.9074725370153272,
      "grad_norm": 6.999782562255859,
      "learning_rate": 6.976986539296571e-06,
      "loss": 0.2513,
      "step": 10450
    },
    {
      "epoch": 0.9118145108766446,
      "grad_norm": 10.487621307373047,
      "learning_rate": 6.96280214213345e-06,
      "loss": 0.2685,
      "step": 10500
    },
    {
      "epoch": 0.9161564847379619,
      "grad_norm": 10.34904670715332,
      "learning_rate": 6.948328267477204e-06,
      "loss": 0.2173,
      "step": 10550
    },
    {
      "epoch": 0.9204984585992793,
      "grad_norm": 10.263396263122559,
      "learning_rate": 6.933854392820959e-06,
      "loss": 0.2394,
      "step": 10600
    },
    {
      "epoch": 0.9248404324605966,
      "grad_norm": 7.749691963195801,
      "learning_rate": 6.919380518164713e-06,
      "loss": 0.3045,
      "step": 10650
    },
    {
      "epoch": 0.929182406321914,
      "grad_norm": 7.5561017990112305,
      "learning_rate": 6.904906643508467e-06,
      "loss": 0.2006,
      "step": 10700
    },
    {
      "epoch": 0.9335243801832313,
      "grad_norm": 9.14453125,
      "learning_rate": 6.890432768852222e-06,
      "loss": 0.246,
      "step": 10750
    },
    {
      "epoch": 0.9378663540445487,
      "grad_norm": 12.95663833618164,
      "learning_rate": 6.875958894195976e-06,
      "loss": 0.2269,
      "step": 10800
    },
    {
      "epoch": 0.9422083279058661,
      "grad_norm": 7.384112358093262,
      "learning_rate": 6.8614850195397305e-06,
      "loss": 0.2313,
      "step": 10850
    },
    {
      "epoch": 0.9465503017671834,
      "grad_norm": 11.830831527709961,
      "learning_rate": 6.847011144883486e-06,
      "loss": 0.2247,
      "step": 10900
    },
    {
      "epoch": 0.9508922756285008,
      "grad_norm": 11.668469429016113,
      "learning_rate": 6.832826747720366e-06,
      "loss": 0.3188,
      "step": 10950
    },
    {
      "epoch": 0.955234249489818,
      "grad_norm": 3.9130442142486572,
      "learning_rate": 6.81835287306412e-06,
      "loss": 0.2325,
      "step": 11000
    },
    {
      "epoch": 0.9595762233511355,
      "grad_norm": 5.120070457458496,
      "learning_rate": 6.803878998407875e-06,
      "loss": 0.2465,
      "step": 11050
    },
    {
      "epoch": 0.9639181972124528,
      "grad_norm": 8.14548397064209,
      "learning_rate": 6.789405123751629e-06,
      "loss": 0.1962,
      "step": 11100
    },
    {
      "epoch": 0.9682601710737702,
      "grad_norm": 8.161116600036621,
      "learning_rate": 6.774931249095383e-06,
      "loss": 0.2031,
      "step": 11150
    },
    {
      "epoch": 0.9726021449350875,
      "grad_norm": 6.700616359710693,
      "learning_rate": 6.760457374439138e-06,
      "loss": 0.2406,
      "step": 11200
    },
    {
      "epoch": 0.9769441187964049,
      "grad_norm": 9.01518440246582,
      "learning_rate": 6.745983499782892e-06,
      "loss": 0.2324,
      "step": 11250
    },
    {
      "epoch": 0.9812860926577222,
      "grad_norm": 8.013750076293945,
      "learning_rate": 6.731509625126646e-06,
      "loss": 0.2223,
      "step": 11300
    },
    {
      "epoch": 0.9856280665190396,
      "grad_norm": 3.7864232063293457,
      "learning_rate": 6.717035750470402e-06,
      "loss": 0.253,
      "step": 11350
    },
    {
      "epoch": 0.989970040380357,
      "grad_norm": 10.278191566467285,
      "learning_rate": 6.702561875814156e-06,
      "loss": 0.2362,
      "step": 11400
    },
    {
      "epoch": 0.9943120142416743,
      "grad_norm": 6.585808753967285,
      "learning_rate": 6.688088001157911e-06,
      "loss": 0.2489,
      "step": 11450
    },
    {
      "epoch": 0.9986539881029917,
      "grad_norm": 7.475987911224365,
      "learning_rate": 6.673614126501665e-06,
      "loss": 0.2333,
      "step": 11500
    },
    {
      "epoch": 0.9999565802613868,
      "eval_loss": 0.22973021864891052,
      "eval_runtime": 158.8031,
      "eval_samples_per_second": 64.457,
      "eval_steps_per_second": 16.114,
      "step": 11515
    }
  ],
  "logging_steps": 50,
  "max_steps": 34545,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.658564141907968e+19,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
