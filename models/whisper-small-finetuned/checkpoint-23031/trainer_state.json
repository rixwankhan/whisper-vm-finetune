{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 23031,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.004341973861317355,
      "grad_norm": 32.08115005493164,
      "learning_rate": 9.98697351280938e-06,
      "loss": 2.7201,
      "step": 50
    },
    {
      "epoch": 0.00868394772263471,
      "grad_norm": 11.602313041687012,
      "learning_rate": 9.972499638153135e-06,
      "loss": 0.8616,
      "step": 100
    },
    {
      "epoch": 0.013025921583952065,
      "grad_norm": 13.351936340332031,
      "learning_rate": 9.95802576349689e-06,
      "loss": 0.3809,
      "step": 150
    },
    {
      "epoch": 0.01736789544526942,
      "grad_norm": 11.841660499572754,
      "learning_rate": 9.943551888840644e-06,
      "loss": 0.3299,
      "step": 200
    },
    {
      "epoch": 0.021709869306586773,
      "grad_norm": 13.042312622070312,
      "learning_rate": 9.929078014184398e-06,
      "loss": 0.3422,
      "step": 250
    },
    {
      "epoch": 0.02605184316790413,
      "grad_norm": 12.432320594787598,
      "learning_rate": 9.914604139528152e-06,
      "loss": 0.3427,
      "step": 300
    },
    {
      "epoch": 0.030393817029221483,
      "grad_norm": 11.445119857788086,
      "learning_rate": 9.900130264871906e-06,
      "loss": 0.3318,
      "step": 350
    },
    {
      "epoch": 0.03473579089053884,
      "grad_norm": 16.4143009185791,
      "learning_rate": 9.885656390215662e-06,
      "loss": 0.2945,
      "step": 400
    },
    {
      "epoch": 0.039077764751856196,
      "grad_norm": 10.369935989379883,
      "learning_rate": 9.871182515559416e-06,
      "loss": 0.3232,
      "step": 450
    },
    {
      "epoch": 0.043419738613173546,
      "grad_norm": 10.7285737991333,
      "learning_rate": 9.856708640903172e-06,
      "loss": 0.3065,
      "step": 500
    },
    {
      "epoch": 0.0477617124744909,
      "grad_norm": 9.987811088562012,
      "learning_rate": 9.842234766246926e-06,
      "loss": 0.2889,
      "step": 550
    },
    {
      "epoch": 0.05210368633580826,
      "grad_norm": 13.18855094909668,
      "learning_rate": 9.82776089159068e-06,
      "loss": 0.359,
      "step": 600
    },
    {
      "epoch": 0.056445660197125616,
      "grad_norm": 7.523106098175049,
      "learning_rate": 9.813287016934434e-06,
      "loss": 0.3753,
      "step": 650
    },
    {
      "epoch": 0.060787634058442966,
      "grad_norm": 8.611462593078613,
      "learning_rate": 9.798813142278188e-06,
      "loss": 0.327,
      "step": 700
    },
    {
      "epoch": 0.06512960791976033,
      "grad_norm": 9.731183052062988,
      "learning_rate": 9.784339267621942e-06,
      "loss": 0.3218,
      "step": 750
    },
    {
      "epoch": 0.06947158178107768,
      "grad_norm": 14.622904777526855,
      "learning_rate": 9.769865392965696e-06,
      "loss": 0.3116,
      "step": 800
    },
    {
      "epoch": 0.07381355564239503,
      "grad_norm": 14.486369132995605,
      "learning_rate": 9.755391518309452e-06,
      "loss": 0.302,
      "step": 850
    },
    {
      "epoch": 0.07815552950371239,
      "grad_norm": 9.997029304504395,
      "learning_rate": 9.740917643653206e-06,
      "loss": 0.3332,
      "step": 900
    },
    {
      "epoch": 0.08249750336502974,
      "grad_norm": 11.677199363708496,
      "learning_rate": 9.726443768996962e-06,
      "loss": 0.2776,
      "step": 950
    },
    {
      "epoch": 0.08683947722634709,
      "grad_norm": 15.453819274902344,
      "learning_rate": 9.711969894340716e-06,
      "loss": 0.304,
      "step": 1000
    },
    {
      "epoch": 0.09118145108766446,
      "grad_norm": 10.257116317749023,
      "learning_rate": 9.69749601968447e-06,
      "loss": 0.3241,
      "step": 1050
    },
    {
      "epoch": 0.0955234249489818,
      "grad_norm": 12.801012992858887,
      "learning_rate": 9.683022145028224e-06,
      "loss": 0.3245,
      "step": 1100
    },
    {
      "epoch": 0.09986539881029916,
      "grad_norm": 9.938461303710938,
      "learning_rate": 9.668548270371979e-06,
      "loss": 0.3146,
      "step": 1150
    },
    {
      "epoch": 0.10420737267161652,
      "grad_norm": 7.490509986877441,
      "learning_rate": 9.654074395715733e-06,
      "loss": 0.2823,
      "step": 1200
    },
    {
      "epoch": 0.10854934653293387,
      "grad_norm": 13.965841293334961,
      "learning_rate": 9.639600521059488e-06,
      "loss": 0.3684,
      "step": 1250
    },
    {
      "epoch": 0.11289132039425123,
      "grad_norm": 12.257745742797852,
      "learning_rate": 9.625126646403243e-06,
      "loss": 0.3316,
      "step": 1300
    },
    {
      "epoch": 0.11723329425556858,
      "grad_norm": 13.204375267028809,
      "learning_rate": 9.610652771746998e-06,
      "loss": 0.2866,
      "step": 1350
    },
    {
      "epoch": 0.12157526811688593,
      "grad_norm": 14.752259254455566,
      "learning_rate": 9.596178897090753e-06,
      "loss": 0.2965,
      "step": 1400
    },
    {
      "epoch": 0.12591724197820328,
      "grad_norm": 14.065028190612793,
      "learning_rate": 9.581705022434507e-06,
      "loss": 0.2953,
      "step": 1450
    },
    {
      "epoch": 0.13025921583952066,
      "grad_norm": 7.947408676147461,
      "learning_rate": 9.56723114777826e-06,
      "loss": 0.3143,
      "step": 1500
    },
    {
      "epoch": 0.134601189700838,
      "grad_norm": 14.14394474029541,
      "learning_rate": 9.552757273122015e-06,
      "loss": 0.2843,
      "step": 1550
    },
    {
      "epoch": 0.13894316356215536,
      "grad_norm": 8.776320457458496,
      "learning_rate": 9.538283398465769e-06,
      "loss": 0.2435,
      "step": 1600
    },
    {
      "epoch": 0.1432851374234727,
      "grad_norm": 8.089349746704102,
      "learning_rate": 9.523809523809525e-06,
      "loss": 0.3011,
      "step": 1650
    },
    {
      "epoch": 0.14762711128479006,
      "grad_norm": 9.590496063232422,
      "learning_rate": 9.509335649153279e-06,
      "loss": 0.2947,
      "step": 1700
    },
    {
      "epoch": 0.1519690851461074,
      "grad_norm": 9.659972190856934,
      "learning_rate": 9.494861774497035e-06,
      "loss": 0.3485,
      "step": 1750
    },
    {
      "epoch": 0.15631105900742479,
      "grad_norm": 10.331656455993652,
      "learning_rate": 9.480387899840789e-06,
      "loss": 0.2765,
      "step": 1800
    },
    {
      "epoch": 0.16065303286874213,
      "grad_norm": 12.779083251953125,
      "learning_rate": 9.465914025184543e-06,
      "loss": 0.2817,
      "step": 1850
    },
    {
      "epoch": 0.16499500673005948,
      "grad_norm": 9.097893714904785,
      "learning_rate": 9.451440150528297e-06,
      "loss": 0.3581,
      "step": 1900
    },
    {
      "epoch": 0.16933698059137683,
      "grad_norm": 18.47726058959961,
      "learning_rate": 9.436966275872051e-06,
      "loss": 0.2617,
      "step": 1950
    },
    {
      "epoch": 0.17367895445269418,
      "grad_norm": 7.92081356048584,
      "learning_rate": 9.422492401215805e-06,
      "loss": 0.3314,
      "step": 2000
    },
    {
      "epoch": 0.17802092831401156,
      "grad_norm": 11.863414764404297,
      "learning_rate": 9.408018526559561e-06,
      "loss": 0.3495,
      "step": 2050
    },
    {
      "epoch": 0.1823629021753289,
      "grad_norm": 12.667139053344727,
      "learning_rate": 9.393544651903315e-06,
      "loss": 0.318,
      "step": 2100
    },
    {
      "epoch": 0.18670487603664626,
      "grad_norm": 13.5122652053833,
      "learning_rate": 9.379070777247071e-06,
      "loss": 0.3017,
      "step": 2150
    },
    {
      "epoch": 0.1910468498979636,
      "grad_norm": 6.8720526695251465,
      "learning_rate": 9.364596902590825e-06,
      "loss": 0.2728,
      "step": 2200
    },
    {
      "epoch": 0.19538882375928096,
      "grad_norm": 15.49057388305664,
      "learning_rate": 9.350123027934579e-06,
      "loss": 0.2858,
      "step": 2250
    },
    {
      "epoch": 0.1997307976205983,
      "grad_norm": 13.840463638305664,
      "learning_rate": 9.335649153278333e-06,
      "loss": 0.2733,
      "step": 2300
    },
    {
      "epoch": 0.2040727714819157,
      "grad_norm": 12.819256782531738,
      "learning_rate": 9.321175278622087e-06,
      "loss": 0.3099,
      "step": 2350
    },
    {
      "epoch": 0.20841474534323304,
      "grad_norm": 14.073617935180664,
      "learning_rate": 9.306701403965841e-06,
      "loss": 0.3347,
      "step": 2400
    },
    {
      "epoch": 0.2127567192045504,
      "grad_norm": 9.651225090026855,
      "learning_rate": 9.292227529309597e-06,
      "loss": 0.3033,
      "step": 2450
    },
    {
      "epoch": 0.21709869306586774,
      "grad_norm": 8.687524795532227,
      "learning_rate": 9.277753654653351e-06,
      "loss": 0.2807,
      "step": 2500
    },
    {
      "epoch": 0.2214406669271851,
      "grad_norm": 10.235136032104492,
      "learning_rate": 9.263279779997107e-06,
      "loss": 0.2196,
      "step": 2550
    },
    {
      "epoch": 0.22578264078850246,
      "grad_norm": 12.453109741210938,
      "learning_rate": 9.248805905340861e-06,
      "loss": 0.336,
      "step": 2600
    },
    {
      "epoch": 0.23012461464981981,
      "grad_norm": 11.39977741241455,
      "learning_rate": 9.234332030684615e-06,
      "loss": 0.287,
      "step": 2650
    },
    {
      "epoch": 0.23446658851113716,
      "grad_norm": 15.636773109436035,
      "learning_rate": 9.21985815602837e-06,
      "loss": 0.2747,
      "step": 2700
    },
    {
      "epoch": 0.2388085623724545,
      "grad_norm": 9.498825073242188,
      "learning_rate": 9.205384281372124e-06,
      "loss": 0.2462,
      "step": 2750
    },
    {
      "epoch": 0.24315053623377186,
      "grad_norm": 3.69565486907959,
      "learning_rate": 9.190910406715878e-06,
      "loss": 0.2816,
      "step": 2800
    },
    {
      "epoch": 0.24749251009508924,
      "grad_norm": 12.666276931762695,
      "learning_rate": 9.176436532059632e-06,
      "loss": 0.3002,
      "step": 2850
    },
    {
      "epoch": 0.25183448395640656,
      "grad_norm": 16.72841453552246,
      "learning_rate": 9.161962657403388e-06,
      "loss": 0.2584,
      "step": 2900
    },
    {
      "epoch": 0.2561764578177239,
      "grad_norm": 11.932791709899902,
      "learning_rate": 9.147488782747142e-06,
      "loss": 0.311,
      "step": 2950
    },
    {
      "epoch": 0.2605184316790413,
      "grad_norm": 7.06049919128418,
      "learning_rate": 9.133014908090898e-06,
      "loss": 0.2333,
      "step": 3000
    },
    {
      "epoch": 0.26486040554035867,
      "grad_norm": 13.139076232910156,
      "learning_rate": 9.118541033434652e-06,
      "loss": 0.2429,
      "step": 3050
    },
    {
      "epoch": 0.269202379401676,
      "grad_norm": 4.549722671508789,
      "learning_rate": 9.104067158778406e-06,
      "loss": 0.2384,
      "step": 3100
    },
    {
      "epoch": 0.27354435326299337,
      "grad_norm": 15.118318557739258,
      "learning_rate": 9.08959328412216e-06,
      "loss": 0.3034,
      "step": 3150
    },
    {
      "epoch": 0.2778863271243107,
      "grad_norm": 11.380433082580566,
      "learning_rate": 9.075119409465914e-06,
      "loss": 0.2701,
      "step": 3200
    },
    {
      "epoch": 0.28222830098562807,
      "grad_norm": 8.537070274353027,
      "learning_rate": 9.060645534809668e-06,
      "loss": 0.2854,
      "step": 3250
    },
    {
      "epoch": 0.2865702748469454,
      "grad_norm": 15.4993314743042,
      "learning_rate": 9.046171660153424e-06,
      "loss": 0.3197,
      "step": 3300
    },
    {
      "epoch": 0.29091224870826277,
      "grad_norm": 39.80760192871094,
      "learning_rate": 9.031697785497178e-06,
      "loss": 0.3389,
      "step": 3350
    },
    {
      "epoch": 0.2952542225695801,
      "grad_norm": 11.710318565368652,
      "learning_rate": 9.017223910840934e-06,
      "loss": 0.2886,
      "step": 3400
    },
    {
      "epoch": 0.29959619643089747,
      "grad_norm": 10.475316047668457,
      "learning_rate": 9.002750036184688e-06,
      "loss": 0.285,
      "step": 3450
    },
    {
      "epoch": 0.3039381702922148,
      "grad_norm": 7.522524833679199,
      "learning_rate": 8.988276161528442e-06,
      "loss": 0.298,
      "step": 3500
    },
    {
      "epoch": 0.3082801441535322,
      "grad_norm": 5.4467244148254395,
      "learning_rate": 8.973802286872196e-06,
      "loss": 0.2792,
      "step": 3550
    },
    {
      "epoch": 0.31262211801484957,
      "grad_norm": 12.941061973571777,
      "learning_rate": 8.95932841221595e-06,
      "loss": 0.2212,
      "step": 3600
    },
    {
      "epoch": 0.3169640918761669,
      "grad_norm": 13.501566886901855,
      "learning_rate": 8.944854537559704e-06,
      "loss": 0.2792,
      "step": 3650
    },
    {
      "epoch": 0.32130606573748427,
      "grad_norm": 5.546044826507568,
      "learning_rate": 8.93038066290346e-06,
      "loss": 0.3064,
      "step": 3700
    },
    {
      "epoch": 0.3256480395988016,
      "grad_norm": 9.782098770141602,
      "learning_rate": 8.915906788247214e-06,
      "loss": 0.2601,
      "step": 3750
    },
    {
      "epoch": 0.32999001346011897,
      "grad_norm": 4.493556022644043,
      "learning_rate": 8.90143291359097e-06,
      "loss": 0.2417,
      "step": 3800
    },
    {
      "epoch": 0.3343319873214363,
      "grad_norm": 10.674678802490234,
      "learning_rate": 8.886959038934724e-06,
      "loss": 0.2525,
      "step": 3850
    },
    {
      "epoch": 0.33867396118275367,
      "grad_norm": 12.951682090759277,
      "learning_rate": 8.872485164278478e-06,
      "loss": 0.2882,
      "step": 3900
    },
    {
      "epoch": 0.343015935044071,
      "grad_norm": 15.413273811340332,
      "learning_rate": 8.858011289622232e-06,
      "loss": 0.268,
      "step": 3950
    },
    {
      "epoch": 0.34735790890538837,
      "grad_norm": 6.657174110412598,
      "learning_rate": 8.843537414965987e-06,
      "loss": 0.2952,
      "step": 4000
    },
    {
      "epoch": 0.3516998827667057,
      "grad_norm": 6.247474670410156,
      "learning_rate": 8.82906354030974e-06,
      "loss": 0.2185,
      "step": 4050
    },
    {
      "epoch": 0.3560418566280231,
      "grad_norm": 14.013585090637207,
      "learning_rate": 8.814589665653496e-06,
      "loss": 0.2911,
      "step": 4100
    },
    {
      "epoch": 0.3603838304893405,
      "grad_norm": 4.614453315734863,
      "learning_rate": 8.80011579099725e-06,
      "loss": 0.2627,
      "step": 4150
    },
    {
      "epoch": 0.3647258043506578,
      "grad_norm": 18.471010208129883,
      "learning_rate": 8.785641916341006e-06,
      "loss": 0.2986,
      "step": 4200
    },
    {
      "epoch": 0.3690677782119752,
      "grad_norm": 20.08515167236328,
      "learning_rate": 8.771457519177886e-06,
      "loss": 0.2659,
      "step": 4250
    },
    {
      "epoch": 0.3734097520732925,
      "grad_norm": 11.523843765258789,
      "learning_rate": 8.75698364452164e-06,
      "loss": 0.2879,
      "step": 4300
    },
    {
      "epoch": 0.37775172593460987,
      "grad_norm": 12.521258354187012,
      "learning_rate": 8.742509769865394e-06,
      "loss": 0.2479,
      "step": 4350
    },
    {
      "epoch": 0.3820936997959272,
      "grad_norm": 4.8445587158203125,
      "learning_rate": 8.728035895209148e-06,
      "loss": 0.3093,
      "step": 4400
    },
    {
      "epoch": 0.38643567365724457,
      "grad_norm": 16.926706314086914,
      "learning_rate": 8.713562020552902e-06,
      "loss": 0.2764,
      "step": 4450
    },
    {
      "epoch": 0.3907776475185619,
      "grad_norm": 12.894941329956055,
      "learning_rate": 8.699088145896656e-06,
      "loss": 0.326,
      "step": 4500
    },
    {
      "epoch": 0.39511962137987927,
      "grad_norm": 7.567624568939209,
      "learning_rate": 8.684614271240412e-06,
      "loss": 0.2442,
      "step": 4550
    },
    {
      "epoch": 0.3994615952411966,
      "grad_norm": 0.5340330600738525,
      "learning_rate": 8.670140396584166e-06,
      "loss": 0.2505,
      "step": 4600
    },
    {
      "epoch": 0.403803569102514,
      "grad_norm": 2.206448554992676,
      "learning_rate": 8.655666521927922e-06,
      "loss": 0.2872,
      "step": 4650
    },
    {
      "epoch": 0.4081455429638314,
      "grad_norm": 3.9290964603424072,
      "learning_rate": 8.641192647271676e-06,
      "loss": 0.264,
      "step": 4700
    },
    {
      "epoch": 0.4124875168251487,
      "grad_norm": 10.728494644165039,
      "learning_rate": 8.62671877261543e-06,
      "loss": 0.3088,
      "step": 4750
    },
    {
      "epoch": 0.4168294906864661,
      "grad_norm": 1.5482255220413208,
      "learning_rate": 8.612244897959184e-06,
      "loss": 0.2577,
      "step": 4800
    },
    {
      "epoch": 0.4211714645477834,
      "grad_norm": 12.54301929473877,
      "learning_rate": 8.597771023302938e-06,
      "loss": 0.2649,
      "step": 4850
    },
    {
      "epoch": 0.4255134384091008,
      "grad_norm": 8.942083358764648,
      "learning_rate": 8.583297148646693e-06,
      "loss": 0.3254,
      "step": 4900
    },
    {
      "epoch": 0.4298554122704181,
      "grad_norm": 6.604653358459473,
      "learning_rate": 8.568823273990448e-06,
      "loss": 0.3005,
      "step": 4950
    },
    {
      "epoch": 0.4341973861317355,
      "grad_norm": 4.268127918243408,
      "learning_rate": 8.554349399334202e-06,
      "loss": 0.2745,
      "step": 5000
    },
    {
      "epoch": 0.4385393599930528,
      "grad_norm": 6.471729755401611,
      "learning_rate": 8.539875524677957e-06,
      "loss": 0.2735,
      "step": 5050
    },
    {
      "epoch": 0.4428813338543702,
      "grad_norm": 15.852076530456543,
      "learning_rate": 8.525401650021712e-06,
      "loss": 0.3188,
      "step": 5100
    },
    {
      "epoch": 0.4472233077156876,
      "grad_norm": 9.784584999084473,
      "learning_rate": 8.510927775365467e-06,
      "loss": 0.2664,
      "step": 5150
    },
    {
      "epoch": 0.45156528157700493,
      "grad_norm": 7.76936674118042,
      "learning_rate": 8.49645390070922e-06,
      "loss": 0.2571,
      "step": 5200
    },
    {
      "epoch": 0.4559072554383223,
      "grad_norm": 11.905091285705566,
      "learning_rate": 8.481980026052975e-06,
      "loss": 0.3088,
      "step": 5250
    },
    {
      "epoch": 0.46024922929963963,
      "grad_norm": 7.778932094573975,
      "learning_rate": 8.467506151396729e-06,
      "loss": 0.2754,
      "step": 5300
    },
    {
      "epoch": 0.464591203160957,
      "grad_norm": 7.64968729019165,
      "learning_rate": 8.453032276740483e-06,
      "loss": 0.253,
      "step": 5350
    },
    {
      "epoch": 0.46893317702227433,
      "grad_norm": 7.020500183105469,
      "learning_rate": 8.438558402084239e-06,
      "loss": 0.2032,
      "step": 5400
    },
    {
      "epoch": 0.4732751508835917,
      "grad_norm": 15.488313674926758,
      "learning_rate": 8.424084527427993e-06,
      "loss": 0.2675,
      "step": 5450
    },
    {
      "epoch": 0.477617124744909,
      "grad_norm": 6.211950302124023,
      "learning_rate": 8.409610652771749e-06,
      "loss": 0.2203,
      "step": 5500
    },
    {
      "epoch": 0.4819590986062264,
      "grad_norm": 11.131321907043457,
      "learning_rate": 8.395136778115503e-06,
      "loss": 0.323,
      "step": 5550
    },
    {
      "epoch": 0.4863010724675437,
      "grad_norm": 7.9977126121521,
      "learning_rate": 8.380662903459257e-06,
      "loss": 0.2231,
      "step": 5600
    },
    {
      "epoch": 0.4906430463288611,
      "grad_norm": 10.198436737060547,
      "learning_rate": 8.366189028803011e-06,
      "loss": 0.2465,
      "step": 5650
    },
    {
      "epoch": 0.4949850201901785,
      "grad_norm": 14.98998737335205,
      "learning_rate": 8.351715154146765e-06,
      "loss": 0.2235,
      "step": 5700
    },
    {
      "epoch": 0.49932699405149583,
      "grad_norm": 13.291168212890625,
      "learning_rate": 8.33724127949052e-06,
      "loss": 0.2082,
      "step": 5750
    },
    {
      "epoch": 0.5036689679128131,
      "grad_norm": 11.353480339050293,
      "learning_rate": 8.322767404834275e-06,
      "loss": 0.2813,
      "step": 5800
    },
    {
      "epoch": 0.5080109417741305,
      "grad_norm": 4.9565815925598145,
      "learning_rate": 8.308293530178029e-06,
      "loss": 0.2223,
      "step": 5850
    },
    {
      "epoch": 0.5123529156354478,
      "grad_norm": 10.184609413146973,
      "learning_rate": 8.293819655521785e-06,
      "loss": 0.2622,
      "step": 5900
    },
    {
      "epoch": 0.5166948894967652,
      "grad_norm": 11.807438850402832,
      "learning_rate": 8.279345780865539e-06,
      "loss": 0.221,
      "step": 5950
    },
    {
      "epoch": 0.5210368633580826,
      "grad_norm": 10.200774192810059,
      "learning_rate": 8.264871906209293e-06,
      "loss": 0.2987,
      "step": 6000
    },
    {
      "epoch": 0.5253788372193999,
      "grad_norm": 12.71509838104248,
      "learning_rate": 8.250398031553047e-06,
      "loss": 0.281,
      "step": 6050
    },
    {
      "epoch": 0.5297208110807173,
      "grad_norm": 6.515493392944336,
      "learning_rate": 8.235924156896801e-06,
      "loss": 0.2731,
      "step": 6100
    },
    {
      "epoch": 0.5340627849420346,
      "grad_norm": 12.207219123840332,
      "learning_rate": 8.221450282240555e-06,
      "loss": 0.1996,
      "step": 6150
    },
    {
      "epoch": 0.538404758803352,
      "grad_norm": 14.700127601623535,
      "learning_rate": 8.206976407584311e-06,
      "loss": 0.2901,
      "step": 6200
    },
    {
      "epoch": 0.5427467326646693,
      "grad_norm": 13.294961929321289,
      "learning_rate": 8.192502532928065e-06,
      "loss": 0.2529,
      "step": 6250
    },
    {
      "epoch": 0.5470887065259867,
      "grad_norm": 7.7809295654296875,
      "learning_rate": 8.178028658271821e-06,
      "loss": 0.2201,
      "step": 6300
    },
    {
      "epoch": 0.551430680387304,
      "grad_norm": 9.105611801147461,
      "learning_rate": 8.163554783615575e-06,
      "loss": 0.2144,
      "step": 6350
    },
    {
      "epoch": 0.5557726542486214,
      "grad_norm": 9.768695831298828,
      "learning_rate": 8.149370386452455e-06,
      "loss": 0.2631,
      "step": 6400
    },
    {
      "epoch": 0.5601146281099387,
      "grad_norm": 15.364813804626465,
      "learning_rate": 8.134896511796209e-06,
      "loss": 0.2801,
      "step": 6450
    },
    {
      "epoch": 0.5644566019712561,
      "grad_norm": 11.26169204711914,
      "learning_rate": 8.120422637139963e-06,
      "loss": 0.2521,
      "step": 6500
    },
    {
      "epoch": 0.5687985758325735,
      "grad_norm": 14.16651725769043,
      "learning_rate": 8.105948762483717e-06,
      "loss": 0.2911,
      "step": 6550
    },
    {
      "epoch": 0.5731405496938908,
      "grad_norm": 7.423428535461426,
      "learning_rate": 8.091474887827471e-06,
      "loss": 0.2962,
      "step": 6600
    },
    {
      "epoch": 0.5774825235552082,
      "grad_norm": 12.954950332641602,
      "learning_rate": 8.077001013171227e-06,
      "loss": 0.2628,
      "step": 6650
    },
    {
      "epoch": 0.5818244974165255,
      "grad_norm": 0.6374977827072144,
      "learning_rate": 8.062527138514981e-06,
      "loss": 0.2317,
      "step": 6700
    },
    {
      "epoch": 0.5861664712778429,
      "grad_norm": 14.547224998474121,
      "learning_rate": 8.048053263858737e-06,
      "loss": 0.2576,
      "step": 6750
    },
    {
      "epoch": 0.5905084451391602,
      "grad_norm": 15.81212043762207,
      "learning_rate": 8.033579389202491e-06,
      "loss": 0.2389,
      "step": 6800
    },
    {
      "epoch": 0.5948504190004776,
      "grad_norm": 6.094769477844238,
      "learning_rate": 8.019105514546245e-06,
      "loss": 0.2705,
      "step": 6850
    },
    {
      "epoch": 0.5991923928617949,
      "grad_norm": 12.700167655944824,
      "learning_rate": 8.00463163989e-06,
      "loss": 0.2271,
      "step": 6900
    },
    {
      "epoch": 0.6035343667231123,
      "grad_norm": 9.446319580078125,
      "learning_rate": 7.990157765233753e-06,
      "loss": 0.1957,
      "step": 6950
    },
    {
      "epoch": 0.6078763405844296,
      "grad_norm": 10.391845703125,
      "learning_rate": 7.975683890577507e-06,
      "loss": 0.2764,
      "step": 7000
    },
    {
      "epoch": 0.612218314445747,
      "grad_norm": 0.8525072932243347,
      "learning_rate": 7.961210015921263e-06,
      "loss": 0.2413,
      "step": 7050
    },
    {
      "epoch": 0.6165602883070644,
      "grad_norm": 13.354928970336914,
      "learning_rate": 7.946736141265017e-06,
      "loss": 0.2644,
      "step": 7100
    },
    {
      "epoch": 0.6209022621683817,
      "grad_norm": 10.913607597351074,
      "learning_rate": 7.932262266608773e-06,
      "loss": 0.2478,
      "step": 7150
    },
    {
      "epoch": 0.6252442360296991,
      "grad_norm": 10.41576099395752,
      "learning_rate": 7.917788391952527e-06,
      "loss": 0.2523,
      "step": 7200
    },
    {
      "epoch": 0.6295862098910164,
      "grad_norm": 9.93879508972168,
      "learning_rate": 7.903314517296281e-06,
      "loss": 0.2313,
      "step": 7250
    },
    {
      "epoch": 0.6339281837523338,
      "grad_norm": 11.395098686218262,
      "learning_rate": 7.888840642640035e-06,
      "loss": 0.2674,
      "step": 7300
    },
    {
      "epoch": 0.6382701576136511,
      "grad_norm": 13.613016128540039,
      "learning_rate": 7.87436676798379e-06,
      "loss": 0.2442,
      "step": 7350
    },
    {
      "epoch": 0.6426121314749685,
      "grad_norm": 7.089151859283447,
      "learning_rate": 7.859892893327544e-06,
      "loss": 0.2313,
      "step": 7400
    },
    {
      "epoch": 0.6469541053362858,
      "grad_norm": 9.300673484802246,
      "learning_rate": 7.845419018671298e-06,
      "loss": 0.2631,
      "step": 7450
    },
    {
      "epoch": 0.6512960791976032,
      "grad_norm": 12.743701934814453,
      "learning_rate": 7.830945144015054e-06,
      "loss": 0.2909,
      "step": 7500
    },
    {
      "epoch": 0.6556380530589205,
      "grad_norm": 7.693624019622803,
      "learning_rate": 7.816471269358808e-06,
      "loss": 0.3017,
      "step": 7550
    },
    {
      "epoch": 0.6599800269202379,
      "grad_norm": 10.756463050842285,
      "learning_rate": 7.801997394702564e-06,
      "loss": 0.2438,
      "step": 7600
    },
    {
      "epoch": 0.6643220007815553,
      "grad_norm": 9.87155818939209,
      "learning_rate": 7.787523520046318e-06,
      "loss": 0.2453,
      "step": 7650
    },
    {
      "epoch": 0.6686639746428726,
      "grad_norm": 4.115950107574463,
      "learning_rate": 7.773049645390072e-06,
      "loss": 0.2131,
      "step": 7700
    },
    {
      "epoch": 0.67300594850419,
      "grad_norm": 0.4190388023853302,
      "learning_rate": 7.758575770733826e-06,
      "loss": 0.2383,
      "step": 7750
    },
    {
      "epoch": 0.6773479223655073,
      "grad_norm": 10.512711524963379,
      "learning_rate": 7.74410189607758e-06,
      "loss": 0.2181,
      "step": 7800
    },
    {
      "epoch": 0.6816898962268247,
      "grad_norm": 9.304518699645996,
      "learning_rate": 7.729628021421334e-06,
      "loss": 0.2388,
      "step": 7850
    },
    {
      "epoch": 0.686031870088142,
      "grad_norm": 6.525651931762695,
      "learning_rate": 7.71515414676509e-06,
      "loss": 0.2645,
      "step": 7900
    },
    {
      "epoch": 0.6903738439494594,
      "grad_norm": 9.819262504577637,
      "learning_rate": 7.700680272108844e-06,
      "loss": 0.247,
      "step": 7950
    },
    {
      "epoch": 0.6947158178107767,
      "grad_norm": 14.438730239868164,
      "learning_rate": 7.6862063974526e-06,
      "loss": 0.2389,
      "step": 8000
    },
    {
      "epoch": 0.6990577916720941,
      "grad_norm": 12.934776306152344,
      "learning_rate": 7.671732522796354e-06,
      "loss": 0.2695,
      "step": 8050
    },
    {
      "epoch": 0.7033997655334114,
      "grad_norm": 10.648255348205566,
      "learning_rate": 7.657258648140108e-06,
      "loss": 0.2091,
      "step": 8100
    },
    {
      "epoch": 0.7077417393947288,
      "grad_norm": 7.91797399520874,
      "learning_rate": 7.642784773483862e-06,
      "loss": 0.2358,
      "step": 8150
    },
    {
      "epoch": 0.7120837132560462,
      "grad_norm": 8.622334480285645,
      "learning_rate": 7.628310898827617e-06,
      "loss": 0.2107,
      "step": 8200
    },
    {
      "epoch": 0.7164256871173635,
      "grad_norm": 10.815421104431152,
      "learning_rate": 7.613837024171371e-06,
      "loss": 0.2201,
      "step": 8250
    },
    {
      "epoch": 0.720767660978681,
      "grad_norm": 12.649157524108887,
      "learning_rate": 7.599363149515125e-06,
      "loss": 0.258,
      "step": 8300
    },
    {
      "epoch": 0.7251096348399982,
      "grad_norm": 13.133886337280273,
      "learning_rate": 7.58488927485888e-06,
      "loss": 0.2818,
      "step": 8350
    },
    {
      "epoch": 0.7294516087013156,
      "grad_norm": 11.359635353088379,
      "learning_rate": 7.570415400202635e-06,
      "loss": 0.2722,
      "step": 8400
    },
    {
      "epoch": 0.7337935825626329,
      "grad_norm": 17.86835479736328,
      "learning_rate": 7.555941525546389e-06,
      "loss": 0.2276,
      "step": 8450
    },
    {
      "epoch": 0.7381355564239503,
      "grad_norm": 20.632299423217773,
      "learning_rate": 7.541467650890144e-06,
      "loss": 0.291,
      "step": 8500
    },
    {
      "epoch": 0.7424775302852676,
      "grad_norm": 8.320937156677246,
      "learning_rate": 7.526993776233898e-06,
      "loss": 0.2789,
      "step": 8550
    },
    {
      "epoch": 0.746819504146585,
      "grad_norm": 10.321586608886719,
      "learning_rate": 7.5125199015776525e-06,
      "loss": 0.2535,
      "step": 8600
    },
    {
      "epoch": 0.7511614780079023,
      "grad_norm": 3.8393821716308594,
      "learning_rate": 7.4980460269214074e-06,
      "loss": 0.2108,
      "step": 8650
    },
    {
      "epoch": 0.7555034518692197,
      "grad_norm": 8.907423973083496,
      "learning_rate": 7.4835721522651616e-06,
      "loss": 0.2765,
      "step": 8700
    },
    {
      "epoch": 0.7598454257305371,
      "grad_norm": 3.0093770027160645,
      "learning_rate": 7.469098277608916e-06,
      "loss": 0.2116,
      "step": 8750
    },
    {
      "epoch": 0.7641873995918544,
      "grad_norm": 2.4784209728240967,
      "learning_rate": 7.4546244029526715e-06,
      "loss": 0.2738,
      "step": 8800
    },
    {
      "epoch": 0.7685293734531718,
      "grad_norm": 4.4596686363220215,
      "learning_rate": 7.440150528296426e-06,
      "loss": 0.2195,
      "step": 8850
    },
    {
      "epoch": 0.7728713473144891,
      "grad_norm": 3.5557031631469727,
      "learning_rate": 7.4256766536401805e-06,
      "loss": 0.2738,
      "step": 8900
    },
    {
      "epoch": 0.7772133211758065,
      "grad_norm": 10.603437423706055,
      "learning_rate": 7.411202778983935e-06,
      "loss": 0.2311,
      "step": 8950
    },
    {
      "epoch": 0.7815552950371238,
      "grad_norm": 14.556783676147461,
      "learning_rate": 7.396728904327689e-06,
      "loss": 0.2405,
      "step": 9000
    },
    {
      "epoch": 0.7858972688984412,
      "grad_norm": 10.350156784057617,
      "learning_rate": 7.382255029671444e-06,
      "loss": 0.2749,
      "step": 9050
    },
    {
      "epoch": 0.7902392427597585,
      "grad_norm": 8.201991081237793,
      "learning_rate": 7.367781155015198e-06,
      "loss": 0.2591,
      "step": 9100
    },
    {
      "epoch": 0.794581216621076,
      "grad_norm": 2.724789619445801,
      "learning_rate": 7.353307280358952e-06,
      "loss": 0.2934,
      "step": 9150
    },
    {
      "epoch": 0.7989231904823932,
      "grad_norm": 5.613165855407715,
      "learning_rate": 7.338833405702708e-06,
      "loss": 0.2337,
      "step": 9200
    },
    {
      "epoch": 0.8032651643437106,
      "grad_norm": 3.3908209800720215,
      "learning_rate": 7.324359531046462e-06,
      "loss": 0.2413,
      "step": 9250
    },
    {
      "epoch": 0.807607138205028,
      "grad_norm": 9.619438171386719,
      "learning_rate": 7.309885656390217e-06,
      "loss": 0.2663,
      "step": 9300
    },
    {
      "epoch": 0.8119491120663453,
      "grad_norm": 6.928030967712402,
      "learning_rate": 7.295411781733971e-06,
      "loss": 0.2713,
      "step": 9350
    },
    {
      "epoch": 0.8162910859276628,
      "grad_norm": 11.707024574279785,
      "learning_rate": 7.280937907077725e-06,
      "loss": 0.2465,
      "step": 9400
    },
    {
      "epoch": 0.82063305978898,
      "grad_norm": 9.797958374023438,
      "learning_rate": 7.26646403242148e-06,
      "loss": 0.2931,
      "step": 9450
    },
    {
      "epoch": 0.8249750336502975,
      "grad_norm": 11.354745864868164,
      "learning_rate": 7.251990157765234e-06,
      "loss": 0.1794,
      "step": 9500
    },
    {
      "epoch": 0.8293170075116147,
      "grad_norm": 13.923330307006836,
      "learning_rate": 7.237516283108988e-06,
      "loss": 0.2276,
      "step": 9550
    },
    {
      "epoch": 0.8336589813729322,
      "grad_norm": 6.454158306121826,
      "learning_rate": 7.223042408452743e-06,
      "loss": 0.2378,
      "step": 9600
    },
    {
      "epoch": 0.8380009552342494,
      "grad_norm": 6.767538547515869,
      "learning_rate": 7.208568533796498e-06,
      "loss": 0.2194,
      "step": 9650
    },
    {
      "epoch": 0.8423429290955669,
      "grad_norm": 4.610179424285889,
      "learning_rate": 7.194094659140253e-06,
      "loss": 0.1802,
      "step": 9700
    },
    {
      "epoch": 0.8466849029568841,
      "grad_norm": 6.4949870109558105,
      "learning_rate": 7.179620784484007e-06,
      "loss": 0.2525,
      "step": 9750
    },
    {
      "epoch": 0.8510268768182015,
      "grad_norm": 6.070311069488525,
      "learning_rate": 7.165146909827761e-06,
      "loss": 0.2412,
      "step": 9800
    },
    {
      "epoch": 0.855368850679519,
      "grad_norm": 11.405903816223145,
      "learning_rate": 7.150673035171516e-06,
      "loss": 0.2727,
      "step": 9850
    },
    {
      "epoch": 0.8597108245408362,
      "grad_norm": 13.383929252624512,
      "learning_rate": 7.13619916051527e-06,
      "loss": 0.2882,
      "step": 9900
    },
    {
      "epoch": 0.8640527984021537,
      "grad_norm": 13.404510498046875,
      "learning_rate": 7.1217252858590245e-06,
      "loss": 0.2219,
      "step": 9950
    },
    {
      "epoch": 0.868394772263471,
      "grad_norm": 9.866695404052734,
      "learning_rate": 7.107251411202779e-06,
      "loss": 0.2302,
      "step": 10000
    },
    {
      "epoch": 0.8727367461247884,
      "grad_norm": 13.462258338928223,
      "learning_rate": 7.092777536546534e-06,
      "loss": 0.244,
      "step": 10050
    },
    {
      "epoch": 0.8770787199861056,
      "grad_norm": 4.718477249145508,
      "learning_rate": 7.078303661890289e-06,
      "loss": 0.2321,
      "step": 10100
    },
    {
      "epoch": 0.881420693847423,
      "grad_norm": 6.899251937866211,
      "learning_rate": 7.0638297872340434e-06,
      "loss": 0.2126,
      "step": 10150
    },
    {
      "epoch": 0.8857626677087403,
      "grad_norm": 7.1671576499938965,
      "learning_rate": 7.0493559125777976e-06,
      "loss": 0.2159,
      "step": 10200
    },
    {
      "epoch": 0.8901046415700578,
      "grad_norm": 13.115740776062012,
      "learning_rate": 7.0348820379215525e-06,
      "loss": 0.244,
      "step": 10250
    },
    {
      "epoch": 0.8944466154313752,
      "grad_norm": 12.494568824768066,
      "learning_rate": 7.020408163265307e-06,
      "loss": 0.2641,
      "step": 10300
    },
    {
      "epoch": 0.8987885892926925,
      "grad_norm": 9.132339477539062,
      "learning_rate": 7.005934288609061e-06,
      "loss": 0.2483,
      "step": 10350
    },
    {
      "epoch": 0.9031305631540099,
      "grad_norm": 8.740550994873047,
      "learning_rate": 6.991460413952816e-06,
      "loss": 0.1968,
      "step": 10400
    },
    {
      "epoch": 0.9074725370153272,
      "grad_norm": 6.999782562255859,
      "learning_rate": 6.976986539296571e-06,
      "loss": 0.2513,
      "step": 10450
    },
    {
      "epoch": 0.9118145108766446,
      "grad_norm": 10.487621307373047,
      "learning_rate": 6.96280214213345e-06,
      "loss": 0.2685,
      "step": 10500
    },
    {
      "epoch": 0.9161564847379619,
      "grad_norm": 10.34904670715332,
      "learning_rate": 6.948328267477204e-06,
      "loss": 0.2173,
      "step": 10550
    },
    {
      "epoch": 0.9204984585992793,
      "grad_norm": 10.263396263122559,
      "learning_rate": 6.933854392820959e-06,
      "loss": 0.2394,
      "step": 10600
    },
    {
      "epoch": 0.9248404324605966,
      "grad_norm": 7.749691963195801,
      "learning_rate": 6.919380518164713e-06,
      "loss": 0.3045,
      "step": 10650
    },
    {
      "epoch": 0.929182406321914,
      "grad_norm": 7.5561017990112305,
      "learning_rate": 6.904906643508467e-06,
      "loss": 0.2006,
      "step": 10700
    },
    {
      "epoch": 0.9335243801832313,
      "grad_norm": 9.14453125,
      "learning_rate": 6.890432768852222e-06,
      "loss": 0.246,
      "step": 10750
    },
    {
      "epoch": 0.9378663540445487,
      "grad_norm": 12.95663833618164,
      "learning_rate": 6.875958894195976e-06,
      "loss": 0.2269,
      "step": 10800
    },
    {
      "epoch": 0.9422083279058661,
      "grad_norm": 7.384112358093262,
      "learning_rate": 6.8614850195397305e-06,
      "loss": 0.2313,
      "step": 10850
    },
    {
      "epoch": 0.9465503017671834,
      "grad_norm": 11.830831527709961,
      "learning_rate": 6.847011144883486e-06,
      "loss": 0.2247,
      "step": 10900
    },
    {
      "epoch": 0.9508922756285008,
      "grad_norm": 11.668469429016113,
      "learning_rate": 6.832826747720366e-06,
      "loss": 0.3188,
      "step": 10950
    },
    {
      "epoch": 0.955234249489818,
      "grad_norm": 3.9130442142486572,
      "learning_rate": 6.81835287306412e-06,
      "loss": 0.2325,
      "step": 11000
    },
    {
      "epoch": 0.9595762233511355,
      "grad_norm": 5.120070457458496,
      "learning_rate": 6.803878998407875e-06,
      "loss": 0.2465,
      "step": 11050
    },
    {
      "epoch": 0.9639181972124528,
      "grad_norm": 8.14548397064209,
      "learning_rate": 6.789405123751629e-06,
      "loss": 0.1962,
      "step": 11100
    },
    {
      "epoch": 0.9682601710737702,
      "grad_norm": 8.161116600036621,
      "learning_rate": 6.774931249095383e-06,
      "loss": 0.2031,
      "step": 11150
    },
    {
      "epoch": 0.9726021449350875,
      "grad_norm": 6.700616359710693,
      "learning_rate": 6.760457374439138e-06,
      "loss": 0.2406,
      "step": 11200
    },
    {
      "epoch": 0.9769441187964049,
      "grad_norm": 9.01518440246582,
      "learning_rate": 6.745983499782892e-06,
      "loss": 0.2324,
      "step": 11250
    },
    {
      "epoch": 0.9812860926577222,
      "grad_norm": 8.013750076293945,
      "learning_rate": 6.731509625126646e-06,
      "loss": 0.2223,
      "step": 11300
    },
    {
      "epoch": 0.9856280665190396,
      "grad_norm": 3.7864232063293457,
      "learning_rate": 6.717035750470402e-06,
      "loss": 0.253,
      "step": 11350
    },
    {
      "epoch": 0.989970040380357,
      "grad_norm": 10.278191566467285,
      "learning_rate": 6.702561875814156e-06,
      "loss": 0.2362,
      "step": 11400
    },
    {
      "epoch": 0.9943120142416743,
      "grad_norm": 6.585808753967285,
      "learning_rate": 6.688088001157911e-06,
      "loss": 0.2489,
      "step": 11450
    },
    {
      "epoch": 0.9986539881029917,
      "grad_norm": 7.475987911224365,
      "learning_rate": 6.673614126501665e-06,
      "loss": 0.2333,
      "step": 11500
    },
    {
      "epoch": 0.9999565802613868,
      "eval_loss": 0.22973021864891052,
      "eval_runtime": 158.8031,
      "eval_samples_per_second": 64.457,
      "eval_steps_per_second": 16.114,
      "step": 11515
    },
    {
      "epoch": 1.002995961964309,
      "grad_norm": 2.4895355701446533,
      "learning_rate": 6.659140251845419e-06,
      "loss": 0.1887,
      "step": 11550
    },
    {
      "epoch": 1.0073379358256263,
      "grad_norm": 6.796756267547607,
      "learning_rate": 6.644666377189174e-06,
      "loss": 0.175,
      "step": 11600
    },
    {
      "epoch": 1.0116799096869438,
      "grad_norm": 6.118704319000244,
      "learning_rate": 6.630192502532928e-06,
      "loss": 0.1286,
      "step": 11650
    },
    {
      "epoch": 1.016021883548261,
      "grad_norm": 2.102407693862915,
      "learning_rate": 6.6157186278766824e-06,
      "loss": 0.1484,
      "step": 11700
    },
    {
      "epoch": 1.0203638574095784,
      "grad_norm": 6.9978156089782715,
      "learning_rate": 6.601244753220437e-06,
      "loss": 0.1353,
      "step": 11750
    },
    {
      "epoch": 1.0247058312708957,
      "grad_norm": 12.549331665039062,
      "learning_rate": 6.586770878564192e-06,
      "loss": 0.1731,
      "step": 11800
    },
    {
      "epoch": 1.0290478051322132,
      "grad_norm": 0.8738523125648499,
      "learning_rate": 6.572297003907947e-06,
      "loss": 0.1472,
      "step": 11850
    },
    {
      "epoch": 1.0333897789935305,
      "grad_norm": 12.091641426086426,
      "learning_rate": 6.557823129251701e-06,
      "loss": 0.12,
      "step": 11900
    },
    {
      "epoch": 1.0377317528548478,
      "grad_norm": 4.691054344177246,
      "learning_rate": 6.5433492545954555e-06,
      "loss": 0.1343,
      "step": 11950
    },
    {
      "epoch": 1.0420737267161653,
      "grad_norm": 11.15015983581543,
      "learning_rate": 6.5288753799392105e-06,
      "loss": 0.1486,
      "step": 12000
    },
    {
      "epoch": 1.0464157005774826,
      "grad_norm": 19.46121597290039,
      "learning_rate": 6.514401505282965e-06,
      "loss": 0.1872,
      "step": 12050
    },
    {
      "epoch": 1.0507576744387999,
      "grad_norm": 8.74670696258545,
      "learning_rate": 6.499927630626719e-06,
      "loss": 0.1351,
      "step": 12100
    },
    {
      "epoch": 1.0550996483001172,
      "grad_norm": 1.0911568403244019,
      "learning_rate": 6.485453755970474e-06,
      "loss": 0.1493,
      "step": 12150
    },
    {
      "epoch": 1.0594416221614347,
      "grad_norm": 15.545437812805176,
      "learning_rate": 6.470979881314229e-06,
      "loss": 0.1405,
      "step": 12200
    },
    {
      "epoch": 1.063783596022752,
      "grad_norm": 16.014005661010742,
      "learning_rate": 6.4565060066579836e-06,
      "loss": 0.1594,
      "step": 12250
    },
    {
      "epoch": 1.0681255698840693,
      "grad_norm": 10.566229820251465,
      "learning_rate": 6.442032132001738e-06,
      "loss": 0.1568,
      "step": 12300
    },
    {
      "epoch": 1.0724675437453866,
      "grad_norm": 5.546818733215332,
      "learning_rate": 6.427558257345492e-06,
      "loss": 0.162,
      "step": 12350
    },
    {
      "epoch": 1.076809517606704,
      "grad_norm": 12.857758522033691,
      "learning_rate": 6.413084382689247e-06,
      "loss": 0.1412,
      "step": 12400
    },
    {
      "epoch": 1.0811514914680214,
      "grad_norm": 4.669007778167725,
      "learning_rate": 6.398610508033001e-06,
      "loss": 0.1747,
      "step": 12450
    },
    {
      "epoch": 1.0854934653293387,
      "grad_norm": 7.152470588684082,
      "learning_rate": 6.384136633376755e-06,
      "loss": 0.1562,
      "step": 12500
    },
    {
      "epoch": 1.0898354391906562,
      "grad_norm": 11.267487525939941,
      "learning_rate": 6.36966275872051e-06,
      "loss": 0.1583,
      "step": 12550
    },
    {
      "epoch": 1.0941774130519735,
      "grad_norm": 12.031243324279785,
      "learning_rate": 6.355188884064265e-06,
      "loss": 0.1545,
      "step": 12600
    },
    {
      "epoch": 1.0985193869132908,
      "grad_norm": 7.165139198303223,
      "learning_rate": 6.34071500940802e-06,
      "loss": 0.1658,
      "step": 12650
    },
    {
      "epoch": 1.102861360774608,
      "grad_norm": 9.312381744384766,
      "learning_rate": 6.326241134751774e-06,
      "loss": 0.1689,
      "step": 12700
    },
    {
      "epoch": 1.1072033346359256,
      "grad_norm": 6.647734642028809,
      "learning_rate": 6.311767260095528e-06,
      "loss": 0.149,
      "step": 12750
    },
    {
      "epoch": 1.1115453084972429,
      "grad_norm": 0.020784372463822365,
      "learning_rate": 6.297293385439283e-06,
      "loss": 0.1683,
      "step": 12800
    },
    {
      "epoch": 1.1158872823585602,
      "grad_norm": 8.196714401245117,
      "learning_rate": 6.282819510783037e-06,
      "loss": 0.1611,
      "step": 12850
    },
    {
      "epoch": 1.1202292562198775,
      "grad_norm": 12.446895599365234,
      "learning_rate": 6.268345636126791e-06,
      "loss": 0.1875,
      "step": 12900
    },
    {
      "epoch": 1.124571230081195,
      "grad_norm": 14.737337112426758,
      "learning_rate": 6.253871761470545e-06,
      "loss": 0.1379,
      "step": 12950
    },
    {
      "epoch": 1.1289132039425123,
      "grad_norm": 7.295111179351807,
      "learning_rate": 6.239397886814301e-06,
      "loss": 0.1062,
      "step": 13000
    },
    {
      "epoch": 1.1332551778038296,
      "grad_norm": 4.94767427444458,
      "learning_rate": 6.224924012158055e-06,
      "loss": 0.1716,
      "step": 13050
    },
    {
      "epoch": 1.137597151665147,
      "grad_norm": 3.360748767852783,
      "learning_rate": 6.21045013750181e-06,
      "loss": 0.1346,
      "step": 13100
    },
    {
      "epoch": 1.1419391255264644,
      "grad_norm": 8.84126091003418,
      "learning_rate": 6.195976262845564e-06,
      "loss": 0.1176,
      "step": 13150
    },
    {
      "epoch": 1.1462810993877817,
      "grad_norm": 5.007967472076416,
      "learning_rate": 6.1815023881893184e-06,
      "loss": 0.1754,
      "step": 13200
    },
    {
      "epoch": 1.150623073249099,
      "grad_norm": 1.278257131576538,
      "learning_rate": 6.167028513533073e-06,
      "loss": 0.1639,
      "step": 13250
    },
    {
      "epoch": 1.1549650471104165,
      "grad_norm": 4.407376766204834,
      "learning_rate": 6.1525546388768275e-06,
      "loss": 0.1605,
      "step": 13300
    },
    {
      "epoch": 1.1593070209717338,
      "grad_norm": 11.04604721069336,
      "learning_rate": 6.138080764220582e-06,
      "loss": 0.1222,
      "step": 13350
    },
    {
      "epoch": 1.163648994833051,
      "grad_norm": 12.066889762878418,
      "learning_rate": 6.1236068895643366e-06,
      "loss": 0.1046,
      "step": 13400
    },
    {
      "epoch": 1.1679909686943684,
      "grad_norm": 8.209555625915527,
      "learning_rate": 6.1091330149080915e-06,
      "loss": 0.1586,
      "step": 13450
    },
    {
      "epoch": 1.1723329425556859,
      "grad_norm": 7.170156955718994,
      "learning_rate": 6.0946591402518465e-06,
      "loss": 0.1218,
      "step": 13500
    },
    {
      "epoch": 1.1766749164170032,
      "grad_norm": 14.487652778625488,
      "learning_rate": 6.080185265595601e-06,
      "loss": 0.1915,
      "step": 13550
    },
    {
      "epoch": 1.1810168902783205,
      "grad_norm": 6.8529839515686035,
      "learning_rate": 6.065711390939355e-06,
      "loss": 0.1129,
      "step": 13600
    },
    {
      "epoch": 1.185358864139638,
      "grad_norm": 9.348575592041016,
      "learning_rate": 6.05123751628311e-06,
      "loss": 0.1528,
      "step": 13650
    },
    {
      "epoch": 1.1897008380009553,
      "grad_norm": 5.676689624786377,
      "learning_rate": 6.036763641626864e-06,
      "loss": 0.1625,
      "step": 13700
    },
    {
      "epoch": 1.1940428118622726,
      "grad_norm": 13.035611152648926,
      "learning_rate": 6.022289766970618e-06,
      "loss": 0.1763,
      "step": 13750
    },
    {
      "epoch": 1.1983847857235899,
      "grad_norm": 11.174485206604004,
      "learning_rate": 6.007815892314373e-06,
      "loss": 0.1428,
      "step": 13800
    },
    {
      "epoch": 1.2027267595849074,
      "grad_norm": 1.6729018688201904,
      "learning_rate": 5.993342017658128e-06,
      "loss": 0.1718,
      "step": 13850
    },
    {
      "epoch": 1.2070687334462247,
      "grad_norm": 6.937321662902832,
      "learning_rate": 5.978868143001883e-06,
      "loss": 0.1085,
      "step": 13900
    },
    {
      "epoch": 1.211410707307542,
      "grad_norm": 2.6701741218566895,
      "learning_rate": 5.964394268345637e-06,
      "loss": 0.1343,
      "step": 13950
    },
    {
      "epoch": 1.2157526811688593,
      "grad_norm": 6.4982380867004395,
      "learning_rate": 5.949920393689391e-06,
      "loss": 0.1584,
      "step": 14000
    },
    {
      "epoch": 1.2200946550301768,
      "grad_norm": 8.566705703735352,
      "learning_rate": 5.935446519033146e-06,
      "loss": 0.1593,
      "step": 14050
    },
    {
      "epoch": 1.224436628891494,
      "grad_norm": 2.0202713012695312,
      "learning_rate": 5.9209726443769e-06,
      "loss": 0.1566,
      "step": 14100
    },
    {
      "epoch": 1.2287786027528114,
      "grad_norm": 5.631886005401611,
      "learning_rate": 5.906498769720654e-06,
      "loss": 0.1839,
      "step": 14150
    },
    {
      "epoch": 1.2331205766141289,
      "grad_norm": 7.408547878265381,
      "learning_rate": 5.892024895064409e-06,
      "loss": 0.1288,
      "step": 14200
    },
    {
      "epoch": 1.2374625504754462,
      "grad_norm": 3.71185040473938,
      "learning_rate": 5.877551020408164e-06,
      "loss": 0.1153,
      "step": 14250
    },
    {
      "epoch": 1.2418045243367635,
      "grad_norm": 5.404465675354004,
      "learning_rate": 5.863077145751919e-06,
      "loss": 0.1844,
      "step": 14300
    },
    {
      "epoch": 1.2461464981980808,
      "grad_norm": 12.6980619430542,
      "learning_rate": 5.848603271095673e-06,
      "loss": 0.1846,
      "step": 14350
    },
    {
      "epoch": 1.2504884720593983,
      "grad_norm": 0.8423546552658081,
      "learning_rate": 5.834129396439427e-06,
      "loss": 0.135,
      "step": 14400
    },
    {
      "epoch": 1.2548304459207156,
      "grad_norm": 5.374547004699707,
      "learning_rate": 5.819655521783182e-06,
      "loss": 0.1453,
      "step": 14450
    },
    {
      "epoch": 1.2591724197820329,
      "grad_norm": 7.896478176116943,
      "learning_rate": 5.805181647126936e-06,
      "loss": 0.1445,
      "step": 14500
    },
    {
      "epoch": 1.2635143936433502,
      "grad_norm": 5.153639793395996,
      "learning_rate": 5.79070777247069e-06,
      "loss": 0.1264,
      "step": 14550
    },
    {
      "epoch": 1.2678563675046677,
      "grad_norm": 7.638331413269043,
      "learning_rate": 5.776233897814445e-06,
      "loss": 0.1268,
      "step": 14600
    },
    {
      "epoch": 1.272198341365985,
      "grad_norm": 5.552703380584717,
      "learning_rate": 5.7617600231581995e-06,
      "loss": 0.1677,
      "step": 14650
    },
    {
      "epoch": 1.2765403152273023,
      "grad_norm": 8.722034454345703,
      "learning_rate": 5.747286148501955e-06,
      "loss": 0.1498,
      "step": 14700
    },
    {
      "epoch": 1.2808822890886198,
      "grad_norm": 5.28520393371582,
      "learning_rate": 5.732812273845709e-06,
      "loss": 0.1263,
      "step": 14750
    },
    {
      "epoch": 1.285224262949937,
      "grad_norm": 0.4377736747264862,
      "learning_rate": 5.7183383991894635e-06,
      "loss": 0.1699,
      "step": 14800
    },
    {
      "epoch": 1.2895662368112544,
      "grad_norm": 0.9347131848335266,
      "learning_rate": 5.7038645245332185e-06,
      "loss": 0.1209,
      "step": 14850
    },
    {
      "epoch": 1.2939082106725717,
      "grad_norm": 9.414371490478516,
      "learning_rate": 5.6893906498769726e-06,
      "loss": 0.1452,
      "step": 14900
    },
    {
      "epoch": 1.2982501845338892,
      "grad_norm": 8.528615951538086,
      "learning_rate": 5.674916775220727e-06,
      "loss": 0.1239,
      "step": 14950
    },
    {
      "epoch": 1.3025921583952065,
      "grad_norm": 7.305627346038818,
      "learning_rate": 5.660442900564481e-06,
      "loss": 0.1117,
      "step": 15000
    },
    {
      "epoch": 1.3069341322565238,
      "grad_norm": 4.432664394378662,
      "learning_rate": 5.645969025908236e-06,
      "loss": 0.1666,
      "step": 15050
    },
    {
      "epoch": 1.311276106117841,
      "grad_norm": 8.12741756439209,
      "learning_rate": 5.631495151251991e-06,
      "loss": 0.1476,
      "step": 15100
    },
    {
      "epoch": 1.3156180799791586,
      "grad_norm": 0.27312299609184265,
      "learning_rate": 5.61731075408887e-06,
      "loss": 0.1639,
      "step": 15150
    },
    {
      "epoch": 1.3199600538404759,
      "grad_norm": 5.976969242095947,
      "learning_rate": 5.602836879432625e-06,
      "loss": 0.1481,
      "step": 15200
    },
    {
      "epoch": 1.3243020277017932,
      "grad_norm": 12.17628288269043,
      "learning_rate": 5.588363004776379e-06,
      "loss": 0.1714,
      "step": 15250
    },
    {
      "epoch": 1.3286440015631107,
      "grad_norm": 2.3492331504821777,
      "learning_rate": 5.573889130120133e-06,
      "loss": 0.1696,
      "step": 15300
    },
    {
      "epoch": 1.332985975424428,
      "grad_norm": 6.673547744750977,
      "learning_rate": 5.559415255463888e-06,
      "loss": 0.1497,
      "step": 15350
    },
    {
      "epoch": 1.3373279492857453,
      "grad_norm": 10.461968421936035,
      "learning_rate": 5.544941380807642e-06,
      "loss": 0.151,
      "step": 15400
    },
    {
      "epoch": 1.3416699231470628,
      "grad_norm": 5.2127299308776855,
      "learning_rate": 5.5304675061513964e-06,
      "loss": 0.1359,
      "step": 15450
    },
    {
      "epoch": 1.34601189700838,
      "grad_norm": 10.900973320007324,
      "learning_rate": 5.515993631495151e-06,
      "loss": 0.1645,
      "step": 15500
    },
    {
      "epoch": 1.3503538708696974,
      "grad_norm": 6.777567386627197,
      "learning_rate": 5.501519756838906e-06,
      "loss": 0.1412,
      "step": 15550
    },
    {
      "epoch": 1.3546958447310147,
      "grad_norm": 5.665555477142334,
      "learning_rate": 5.487045882182661e-06,
      "loss": 0.1334,
      "step": 15600
    },
    {
      "epoch": 1.359037818592332,
      "grad_norm": 6.394235610961914,
      "learning_rate": 5.4725720075264154e-06,
      "loss": 0.1389,
      "step": 15650
    },
    {
      "epoch": 1.3633797924536495,
      "grad_norm": 7.386012077331543,
      "learning_rate": 5.4580981328701695e-06,
      "loss": 0.1534,
      "step": 15700
    },
    {
      "epoch": 1.3677217663149668,
      "grad_norm": 14.629314422607422,
      "learning_rate": 5.4436242582139245e-06,
      "loss": 0.1852,
      "step": 15750
    },
    {
      "epoch": 1.372063740176284,
      "grad_norm": 0.6826161742210388,
      "learning_rate": 5.429150383557679e-06,
      "loss": 0.1459,
      "step": 15800
    },
    {
      "epoch": 1.3764057140376016,
      "grad_norm": 9.265501022338867,
      "learning_rate": 5.414676508901433e-06,
      "loss": 0.1522,
      "step": 15850
    },
    {
      "epoch": 1.3807476878989189,
      "grad_norm": 6.414170742034912,
      "learning_rate": 5.400202634245188e-06,
      "loss": 0.1615,
      "step": 15900
    },
    {
      "epoch": 1.3850896617602362,
      "grad_norm": 8.480489730834961,
      "learning_rate": 5.385728759588943e-06,
      "loss": 0.1398,
      "step": 15950
    },
    {
      "epoch": 1.3894316356215537,
      "grad_norm": 8.438610076904297,
      "learning_rate": 5.371254884932698e-06,
      "loss": 0.1657,
      "step": 16000
    },
    {
      "epoch": 1.393773609482871,
      "grad_norm": 9.783675193786621,
      "learning_rate": 5.356781010276452e-06,
      "loss": 0.1656,
      "step": 16050
    },
    {
      "epoch": 1.3981155833441883,
      "grad_norm": 10.249602317810059,
      "learning_rate": 5.342307135620206e-06,
      "loss": 0.141,
      "step": 16100
    },
    {
      "epoch": 1.4024575572055056,
      "grad_norm": 1.1902185678482056,
      "learning_rate": 5.327833260963961e-06,
      "loss": 0.0986,
      "step": 16150
    },
    {
      "epoch": 1.4067995310668229,
      "grad_norm": 18.99185562133789,
      "learning_rate": 5.313359386307715e-06,
      "loss": 0.1236,
      "step": 16200
    },
    {
      "epoch": 1.4111415049281404,
      "grad_norm": 7.957430839538574,
      "learning_rate": 5.298885511651469e-06,
      "loss": 0.1832,
      "step": 16250
    },
    {
      "epoch": 1.4154834787894577,
      "grad_norm": 8.840742111206055,
      "learning_rate": 5.284411636995224e-06,
      "loss": 0.1175,
      "step": 16300
    },
    {
      "epoch": 1.419825452650775,
      "grad_norm": 8.315855979919434,
      "learning_rate": 5.269937762338978e-06,
      "loss": 0.1502,
      "step": 16350
    },
    {
      "epoch": 1.4241674265120925,
      "grad_norm": 10.64714527130127,
      "learning_rate": 5.255463887682734e-06,
      "loss": 0.1416,
      "step": 16400
    },
    {
      "epoch": 1.4285094003734098,
      "grad_norm": 9.392339706420898,
      "learning_rate": 5.240990013026488e-06,
      "loss": 0.1501,
      "step": 16450
    },
    {
      "epoch": 1.432851374234727,
      "grad_norm": 6.508515357971191,
      "learning_rate": 5.226516138370242e-06,
      "loss": 0.1356,
      "step": 16500
    },
    {
      "epoch": 1.4371933480960446,
      "grad_norm": 12.240583419799805,
      "learning_rate": 5.212042263713997e-06,
      "loss": 0.1318,
      "step": 16550
    },
    {
      "epoch": 1.441535321957362,
      "grad_norm": 9.682429313659668,
      "learning_rate": 5.197568389057751e-06,
      "loss": 0.1392,
      "step": 16600
    },
    {
      "epoch": 1.4458772958186792,
      "grad_norm": 6.940093517303467,
      "learning_rate": 5.183094514401505e-06,
      "loss": 0.1288,
      "step": 16650
    },
    {
      "epoch": 1.4502192696799965,
      "grad_norm": 7.383029937744141,
      "learning_rate": 5.16862063974526e-06,
      "loss": 0.1638,
      "step": 16700
    },
    {
      "epoch": 1.4545612435413138,
      "grad_norm": 8.015626907348633,
      "learning_rate": 5.154146765089014e-06,
      "loss": 0.1337,
      "step": 16750
    },
    {
      "epoch": 1.4589032174026313,
      "grad_norm": 4.140705108642578,
      "learning_rate": 5.13967289043277e-06,
      "loss": 0.1572,
      "step": 16800
    },
    {
      "epoch": 1.4632451912639486,
      "grad_norm": 4.263915061950684,
      "learning_rate": 5.125199015776524e-06,
      "loss": 0.1591,
      "step": 16850
    },
    {
      "epoch": 1.4675871651252659,
      "grad_norm": 7.539843559265137,
      "learning_rate": 5.110725141120278e-06,
      "loss": 0.1663,
      "step": 16900
    },
    {
      "epoch": 1.4719291389865834,
      "grad_norm": 6.80403470993042,
      "learning_rate": 5.096251266464033e-06,
      "loss": 0.1443,
      "step": 16950
    },
    {
      "epoch": 1.4762711128479007,
      "grad_norm": 7.334268569946289,
      "learning_rate": 5.081777391807787e-06,
      "loss": 0.1345,
      "step": 17000
    },
    {
      "epoch": 1.480613086709218,
      "grad_norm": 21.538869857788086,
      "learning_rate": 5.0673035171515415e-06,
      "loss": 0.1439,
      "step": 17050
    },
    {
      "epoch": 1.4849550605705355,
      "grad_norm": 9.157646179199219,
      "learning_rate": 5.0528296424952965e-06,
      "loss": 0.1883,
      "step": 17100
    },
    {
      "epoch": 1.4892970344318528,
      "grad_norm": 10.004467964172363,
      "learning_rate": 5.038355767839051e-06,
      "loss": 0.1345,
      "step": 17150
    },
    {
      "epoch": 1.49363900829317,
      "grad_norm": 8.288803100585938,
      "learning_rate": 5.0238818931828055e-06,
      "loss": 0.1418,
      "step": 17200
    },
    {
      "epoch": 1.4979809821544874,
      "grad_norm": 6.881669044494629,
      "learning_rate": 5.009697496019685e-06,
      "loss": 0.141,
      "step": 17250
    },
    {
      "epoch": 1.5023229560158047,
      "grad_norm": 8.799572944641113,
      "learning_rate": 4.995223621363439e-06,
      "loss": 0.1546,
      "step": 17300
    },
    {
      "epoch": 1.5066649298771222,
      "grad_norm": 6.629570960998535,
      "learning_rate": 4.980749746707194e-06,
      "loss": 0.1725,
      "step": 17350
    },
    {
      "epoch": 1.5110069037384395,
      "grad_norm": 10.236489295959473,
      "learning_rate": 4.966275872050948e-06,
      "loss": 0.1267,
      "step": 17400
    },
    {
      "epoch": 1.5153488775997568,
      "grad_norm": 4.510442733764648,
      "learning_rate": 4.951801997394703e-06,
      "loss": 0.1569,
      "step": 17450
    },
    {
      "epoch": 1.5196908514610743,
      "grad_norm": 11.930350303649902,
      "learning_rate": 4.937328122738457e-06,
      "loss": 0.1326,
      "step": 17500
    },
    {
      "epoch": 1.5240328253223916,
      "grad_norm": 11.577521324157715,
      "learning_rate": 4.922854248082212e-06,
      "loss": 0.1689,
      "step": 17550
    },
    {
      "epoch": 1.5283747991837089,
      "grad_norm": 7.687832832336426,
      "learning_rate": 4.908380373425966e-06,
      "loss": 0.1633,
      "step": 17600
    },
    {
      "epoch": 1.5327167730450264,
      "grad_norm": 10.742979049682617,
      "learning_rate": 4.893906498769721e-06,
      "loss": 0.1631,
      "step": 17650
    },
    {
      "epoch": 1.5370587469063435,
      "grad_norm": 12.676881790161133,
      "learning_rate": 4.879432624113475e-06,
      "loss": 0.1466,
      "step": 17700
    },
    {
      "epoch": 1.541400720767661,
      "grad_norm": 7.963159084320068,
      "learning_rate": 4.86495874945723e-06,
      "loss": 0.1602,
      "step": 17750
    },
    {
      "epoch": 1.5457426946289783,
      "grad_norm": 8.404998779296875,
      "learning_rate": 4.850484874800984e-06,
      "loss": 0.1426,
      "step": 17800
    },
    {
      "epoch": 1.5500846684902956,
      "grad_norm": 12.583954811096191,
      "learning_rate": 4.836011000144739e-06,
      "loss": 0.1424,
      "step": 17850
    },
    {
      "epoch": 1.554426642351613,
      "grad_norm": 10.515045166015625,
      "learning_rate": 4.8215371254884934e-06,
      "loss": 0.1388,
      "step": 17900
    },
    {
      "epoch": 1.5587686162129304,
      "grad_norm": 0.09036704897880554,
      "learning_rate": 4.807063250832248e-06,
      "loss": 0.1354,
      "step": 17950
    },
    {
      "epoch": 1.5631105900742477,
      "grad_norm": 3.9979803562164307,
      "learning_rate": 4.7925893761760025e-06,
      "loss": 0.16,
      "step": 18000
    },
    {
      "epoch": 1.5674525639355652,
      "grad_norm": 10.055344581604004,
      "learning_rate": 4.7781155015197575e-06,
      "loss": 0.1765,
      "step": 18050
    },
    {
      "epoch": 1.5717945377968825,
      "grad_norm": 6.515308856964111,
      "learning_rate": 4.763641626863512e-06,
      "loss": 0.1497,
      "step": 18100
    },
    {
      "epoch": 1.5761365116581998,
      "grad_norm": 4.9170966148376465,
      "learning_rate": 4.749167752207266e-06,
      "loss": 0.1309,
      "step": 18150
    },
    {
      "epoch": 1.5804784855195173,
      "grad_norm": 9.118842124938965,
      "learning_rate": 4.734693877551021e-06,
      "loss": 0.1611,
      "step": 18200
    },
    {
      "epoch": 1.5848204593808344,
      "grad_norm": 4.670436859130859,
      "learning_rate": 4.720220002894776e-06,
      "loss": 0.1671,
      "step": 18250
    },
    {
      "epoch": 1.589162433242152,
      "grad_norm": 5.8963165283203125,
      "learning_rate": 4.70574612823853e-06,
      "loss": 0.155,
      "step": 18300
    },
    {
      "epoch": 1.5935044071034692,
      "grad_norm": 0.9755913019180298,
      "learning_rate": 4.691272253582284e-06,
      "loss": 0.1451,
      "step": 18350
    },
    {
      "epoch": 1.5978463809647865,
      "grad_norm": 2.514676570892334,
      "learning_rate": 4.676798378926039e-06,
      "loss": 0.1874,
      "step": 18400
    },
    {
      "epoch": 1.602188354826104,
      "grad_norm": 6.621218681335449,
      "learning_rate": 4.662324504269794e-06,
      "loss": 0.1527,
      "step": 18450
    },
    {
      "epoch": 1.6065303286874213,
      "grad_norm": 6.083352088928223,
      "learning_rate": 4.647850629613548e-06,
      "loss": 0.1522,
      "step": 18500
    },
    {
      "epoch": 1.6108723025487386,
      "grad_norm": 7.968784332275391,
      "learning_rate": 4.633376754957302e-06,
      "loss": 0.1157,
      "step": 18550
    },
    {
      "epoch": 1.615214276410056,
      "grad_norm": 3.370387315750122,
      "learning_rate": 4.618902880301057e-06,
      "loss": 0.1205,
      "step": 18600
    },
    {
      "epoch": 1.6195562502713734,
      "grad_norm": 7.180332660675049,
      "learning_rate": 4.604429005644812e-06,
      "loss": 0.1302,
      "step": 18650
    },
    {
      "epoch": 1.6238982241326907,
      "grad_norm": 0.08418329805135727,
      "learning_rate": 4.589955130988566e-06,
      "loss": 0.1485,
      "step": 18700
    },
    {
      "epoch": 1.6282401979940082,
      "grad_norm": 9.862198829650879,
      "learning_rate": 4.57548125633232e-06,
      "loss": 0.1407,
      "step": 18750
    },
    {
      "epoch": 1.6325821718553253,
      "grad_norm": 8.546820640563965,
      "learning_rate": 4.561007381676075e-06,
      "loss": 0.1593,
      "step": 18800
    },
    {
      "epoch": 1.6369241457166428,
      "grad_norm": 8.208939552307129,
      "learning_rate": 4.54653350701983e-06,
      "loss": 0.1009,
      "step": 18850
    },
    {
      "epoch": 1.64126611957796,
      "grad_norm": 9.600082397460938,
      "learning_rate": 4.532059632363584e-06,
      "loss": 0.1497,
      "step": 18900
    },
    {
      "epoch": 1.6456080934392774,
      "grad_norm": 6.318692207336426,
      "learning_rate": 4.517585757707338e-06,
      "loss": 0.1526,
      "step": 18950
    },
    {
      "epoch": 1.649950067300595,
      "grad_norm": 8.331518173217773,
      "learning_rate": 4.503111883051093e-06,
      "loss": 0.1279,
      "step": 19000
    },
    {
      "epoch": 1.6542920411619122,
      "grad_norm": 8.760932922363281,
      "learning_rate": 4.488638008394848e-06,
      "loss": 0.1117,
      "step": 19050
    },
    {
      "epoch": 1.6586340150232295,
      "grad_norm": 5.412656784057617,
      "learning_rate": 4.474164133738602e-06,
      "loss": 0.1405,
      "step": 19100
    },
    {
      "epoch": 1.662975988884547,
      "grad_norm": 0.18343329429626465,
      "learning_rate": 4.459690259082356e-06,
      "loss": 0.1385,
      "step": 19150
    },
    {
      "epoch": 1.6673179627458643,
      "grad_norm": 1.2332340478897095,
      "learning_rate": 4.445216384426111e-06,
      "loss": 0.1096,
      "step": 19200
    },
    {
      "epoch": 1.6716599366071816,
      "grad_norm": 8.579971313476562,
      "learning_rate": 4.430742509769866e-06,
      "loss": 0.1522,
      "step": 19250
    },
    {
      "epoch": 1.6760019104684991,
      "grad_norm": 11.554192543029785,
      "learning_rate": 4.41626863511362e-06,
      "loss": 0.1487,
      "step": 19300
    },
    {
      "epoch": 1.6803438843298162,
      "grad_norm": 4.856355667114258,
      "learning_rate": 4.4020842379505e-06,
      "loss": 0.1479,
      "step": 19350
    },
    {
      "epoch": 1.6846858581911337,
      "grad_norm": 2.942544937133789,
      "learning_rate": 4.387610363294254e-06,
      "loss": 0.1119,
      "step": 19400
    },
    {
      "epoch": 1.689027832052451,
      "grad_norm": 2.100930690765381,
      "learning_rate": 4.373136488638009e-06,
      "loss": 0.1388,
      "step": 19450
    },
    {
      "epoch": 1.6933698059137683,
      "grad_norm": 0.6170673370361328,
      "learning_rate": 4.358662613981764e-06,
      "loss": 0.1314,
      "step": 19500
    },
    {
      "epoch": 1.6977117797750858,
      "grad_norm": 4.570499420166016,
      "learning_rate": 4.344188739325518e-06,
      "loss": 0.1695,
      "step": 19550
    },
    {
      "epoch": 1.702053753636403,
      "grad_norm": 9.56963062286377,
      "learning_rate": 4.329714864669272e-06,
      "loss": 0.1226,
      "step": 19600
    },
    {
      "epoch": 1.7063957274977204,
      "grad_norm": 5.0290350914001465,
      "learning_rate": 4.315240990013027e-06,
      "loss": 0.1508,
      "step": 19650
    },
    {
      "epoch": 1.710737701359038,
      "grad_norm": 11.994057655334473,
      "learning_rate": 4.300767115356781e-06,
      "loss": 0.1797,
      "step": 19700
    },
    {
      "epoch": 1.7150796752203552,
      "grad_norm": 4.463140487670898,
      "learning_rate": 4.286293240700536e-06,
      "loss": 0.1461,
      "step": 19750
    },
    {
      "epoch": 1.7194216490816725,
      "grad_norm": 4.990943908691406,
      "learning_rate": 4.27181936604429e-06,
      "loss": 0.1524,
      "step": 19800
    },
    {
      "epoch": 1.72376362294299,
      "grad_norm": 6.280303001403809,
      "learning_rate": 4.257345491388045e-06,
      "loss": 0.1422,
      "step": 19850
    },
    {
      "epoch": 1.728105596804307,
      "grad_norm": 5.439699172973633,
      "learning_rate": 4.242871616731799e-06,
      "loss": 0.1045,
      "step": 19900
    },
    {
      "epoch": 1.7324475706656246,
      "grad_norm": 6.375192165374756,
      "learning_rate": 4.228397742075554e-06,
      "loss": 0.1001,
      "step": 19950
    },
    {
      "epoch": 1.736789544526942,
      "grad_norm": 12.014942169189453,
      "learning_rate": 4.213923867419308e-06,
      "loss": 0.1702,
      "step": 20000
    },
    {
      "epoch": 1.7411315183882592,
      "grad_norm": 7.028641223907471,
      "learning_rate": 4.199449992763062e-06,
      "loss": 0.1177,
      "step": 20050
    },
    {
      "epoch": 1.7454734922495767,
      "grad_norm": 18.258798599243164,
      "learning_rate": 4.184976118106817e-06,
      "loss": 0.1513,
      "step": 20100
    },
    {
      "epoch": 1.749815466110894,
      "grad_norm": 10.809378623962402,
      "learning_rate": 4.170502243450572e-06,
      "loss": 0.138,
      "step": 20150
    },
    {
      "epoch": 1.7541574399722113,
      "grad_norm": 10.029609680175781,
      "learning_rate": 4.156028368794326e-06,
      "loss": 0.134,
      "step": 20200
    },
    {
      "epoch": 1.7584994138335288,
      "grad_norm": 4.14710807800293,
      "learning_rate": 4.1415544941380805e-06,
      "loss": 0.1448,
      "step": 20250
    },
    {
      "epoch": 1.762841387694846,
      "grad_norm": 7.409153461456299,
      "learning_rate": 4.1270806194818355e-06,
      "loss": 0.1332,
      "step": 20300
    },
    {
      "epoch": 1.7671833615561634,
      "grad_norm": 9.64983081817627,
      "learning_rate": 4.1126067448255904e-06,
      "loss": 0.1416,
      "step": 20350
    },
    {
      "epoch": 1.771525335417481,
      "grad_norm": 0.016156112775206566,
      "learning_rate": 4.0981328701693445e-06,
      "loss": 0.1428,
      "step": 20400
    },
    {
      "epoch": 1.775867309278798,
      "grad_norm": 6.8022050857543945,
      "learning_rate": 4.083658995513099e-06,
      "loss": 0.1286,
      "step": 20450
    },
    {
      "epoch": 1.7802092831401155,
      "grad_norm": 2.9759087562561035,
      "learning_rate": 4.069185120856854e-06,
      "loss": 0.1372,
      "step": 20500
    },
    {
      "epoch": 1.7845512570014328,
      "grad_norm": 9.457865715026855,
      "learning_rate": 4.0547112462006086e-06,
      "loss": 0.1482,
      "step": 20550
    },
    {
      "epoch": 1.78889323086275,
      "grad_norm": 1.2885161638259888,
      "learning_rate": 4.040237371544363e-06,
      "loss": 0.1411,
      "step": 20600
    },
    {
      "epoch": 1.7932352047240676,
      "grad_norm": 8.49577808380127,
      "learning_rate": 4.025763496888117e-06,
      "loss": 0.1596,
      "step": 20650
    },
    {
      "epoch": 1.797577178585385,
      "grad_norm": 3.6167070865631104,
      "learning_rate": 4.011289622231872e-06,
      "loss": 0.1424,
      "step": 20700
    },
    {
      "epoch": 1.8019191524467022,
      "grad_norm": 2.6539206504821777,
      "learning_rate": 3.996815747575627e-06,
      "loss": 0.1328,
      "step": 20750
    },
    {
      "epoch": 1.8062611263080197,
      "grad_norm": 5.883168697357178,
      "learning_rate": 3.982341872919381e-06,
      "loss": 0.1268,
      "step": 20800
    },
    {
      "epoch": 1.810603100169337,
      "grad_norm": 6.293718338012695,
      "learning_rate": 3.967867998263135e-06,
      "loss": 0.1356,
      "step": 20850
    },
    {
      "epoch": 1.8149450740306543,
      "grad_norm": 7.67991828918457,
      "learning_rate": 3.95339412360689e-06,
      "loss": 0.1119,
      "step": 20900
    },
    {
      "epoch": 1.8192870478919718,
      "grad_norm": 9.023368835449219,
      "learning_rate": 3.938920248950645e-06,
      "loss": 0.1614,
      "step": 20950
    },
    {
      "epoch": 1.823629021753289,
      "grad_norm": 13.551576614379883,
      "learning_rate": 3.924446374294399e-06,
      "loss": 0.1653,
      "step": 21000
    },
    {
      "epoch": 1.8279709956146064,
      "grad_norm": 7.216656684875488,
      "learning_rate": 3.909972499638153e-06,
      "loss": 0.1446,
      "step": 21050
    },
    {
      "epoch": 1.8323129694759237,
      "grad_norm": 13.925249099731445,
      "learning_rate": 3.895498624981908e-06,
      "loss": 0.1075,
      "step": 21100
    },
    {
      "epoch": 1.836654943337241,
      "grad_norm": 7.241964817047119,
      "learning_rate": 3.881024750325663e-06,
      "loss": 0.1382,
      "step": 21150
    },
    {
      "epoch": 1.8409969171985585,
      "grad_norm": 2.9219863414764404,
      "learning_rate": 3.866550875669417e-06,
      "loss": 0.1132,
      "step": 21200
    },
    {
      "epoch": 1.8453388910598758,
      "grad_norm": 9.134288787841797,
      "learning_rate": 3.852077001013171e-06,
      "loss": 0.1412,
      "step": 21250
    },
    {
      "epoch": 1.849680864921193,
      "grad_norm": 4.604516506195068,
      "learning_rate": 3.837603126356926e-06,
      "loss": 0.1318,
      "step": 21300
    },
    {
      "epoch": 1.8540228387825106,
      "grad_norm": 0.3576798737049103,
      "learning_rate": 3.823129251700681e-06,
      "loss": 0.1255,
      "step": 21350
    },
    {
      "epoch": 1.858364812643828,
      "grad_norm": 0.4319687485694885,
      "learning_rate": 3.80894485453756e-06,
      "loss": 0.1328,
      "step": 21400
    },
    {
      "epoch": 1.8627067865051452,
      "grad_norm": 1.7280389070510864,
      "learning_rate": 3.7944709798813146e-06,
      "loss": 0.1386,
      "step": 21450
    },
    {
      "epoch": 1.8670487603664627,
      "grad_norm": 1.2364240884780884,
      "learning_rate": 3.7799971052250687e-06,
      "loss": 0.1617,
      "step": 21500
    },
    {
      "epoch": 1.8713907342277798,
      "grad_norm": 10.524025917053223,
      "learning_rate": 3.7655232305688237e-06,
      "loss": 0.1643,
      "step": 21550
    },
    {
      "epoch": 1.8757327080890973,
      "grad_norm": 8.031953811645508,
      "learning_rate": 3.7510493559125782e-06,
      "loss": 0.1748,
      "step": 21600
    },
    {
      "epoch": 1.8800746819504146,
      "grad_norm": 4.875488758087158,
      "learning_rate": 3.7365754812563327e-06,
      "loss": 0.1507,
      "step": 21650
    },
    {
      "epoch": 1.884416655811732,
      "grad_norm": 7.984673976898193,
      "learning_rate": 3.722101606600087e-06,
      "loss": 0.131,
      "step": 21700
    },
    {
      "epoch": 1.8887586296730494,
      "grad_norm": 0.16609551012516022,
      "learning_rate": 3.7076277319438414e-06,
      "loss": 0.13,
      "step": 21750
    },
    {
      "epoch": 1.8931006035343667,
      "grad_norm": 7.161849498748779,
      "learning_rate": 3.6931538572875963e-06,
      "loss": 0.1393,
      "step": 21800
    },
    {
      "epoch": 1.897442577395684,
      "grad_norm": 7.236243724822998,
      "learning_rate": 3.678679982631351e-06,
      "loss": 0.129,
      "step": 21850
    },
    {
      "epoch": 1.9017845512570015,
      "grad_norm": 10.374253273010254,
      "learning_rate": 3.664206107975105e-06,
      "loss": 0.1368,
      "step": 21900
    },
    {
      "epoch": 1.9061265251183188,
      "grad_norm": 2.0947864055633545,
      "learning_rate": 3.6497322333188595e-06,
      "loss": 0.1172,
      "step": 21950
    },
    {
      "epoch": 1.910468498979636,
      "grad_norm": 6.918741703033447,
      "learning_rate": 3.6352583586626145e-06,
      "loss": 0.1496,
      "step": 22000
    },
    {
      "epoch": 1.9148104728409536,
      "grad_norm": 7.337772846221924,
      "learning_rate": 3.620784484006369e-06,
      "loss": 0.1176,
      "step": 22050
    },
    {
      "epoch": 1.9191524467022707,
      "grad_norm": 0.9349635243415833,
      "learning_rate": 3.606310609350123e-06,
      "loss": 0.1231,
      "step": 22100
    },
    {
      "epoch": 1.9234944205635882,
      "grad_norm": 9.466097831726074,
      "learning_rate": 3.5918367346938777e-06,
      "loss": 0.1161,
      "step": 22150
    },
    {
      "epoch": 1.9278363944249055,
      "grad_norm": 1.3035846948623657,
      "learning_rate": 3.5773628600376326e-06,
      "loss": 0.1522,
      "step": 22200
    },
    {
      "epoch": 1.9321783682862228,
      "grad_norm": 8.847750663757324,
      "learning_rate": 3.562888985381387e-06,
      "loss": 0.1666,
      "step": 22250
    },
    {
      "epoch": 1.9365203421475403,
      "grad_norm": 9.673260688781738,
      "learning_rate": 3.5484151107251413e-06,
      "loss": 0.1778,
      "step": 22300
    },
    {
      "epoch": 1.9408623160088576,
      "grad_norm": 5.941328048706055,
      "learning_rate": 3.533941236068896e-06,
      "loss": 0.1482,
      "step": 22350
    },
    {
      "epoch": 1.945204289870175,
      "grad_norm": 4.996196269989014,
      "learning_rate": 3.5194673614126507e-06,
      "loss": 0.1375,
      "step": 22400
    },
    {
      "epoch": 1.9495462637314924,
      "grad_norm": 14.44809627532959,
      "learning_rate": 3.504993486756405e-06,
      "loss": 0.0934,
      "step": 22450
    },
    {
      "epoch": 1.9538882375928097,
      "grad_norm": 2.986774444580078,
      "learning_rate": 3.4905196121001594e-06,
      "loss": 0.0977,
      "step": 22500
    },
    {
      "epoch": 1.958230211454127,
      "grad_norm": 0.16753756999969482,
      "learning_rate": 3.476045737443914e-06,
      "loss": 0.1383,
      "step": 22550
    },
    {
      "epoch": 1.9625721853154445,
      "grad_norm": 9.141763687133789,
      "learning_rate": 3.461571862787669e-06,
      "loss": 0.1123,
      "step": 22600
    },
    {
      "epoch": 1.9669141591767616,
      "grad_norm": 11.578398704528809,
      "learning_rate": 3.447097988131423e-06,
      "loss": 0.1295,
      "step": 22650
    },
    {
      "epoch": 1.9712561330380791,
      "grad_norm": 6.170989036560059,
      "learning_rate": 3.4326241134751775e-06,
      "loss": 0.129,
      "step": 22700
    },
    {
      "epoch": 1.9755981068993964,
      "grad_norm": 8.633371353149414,
      "learning_rate": 3.418150238818932e-06,
      "loss": 0.1252,
      "step": 22750
    },
    {
      "epoch": 1.9799400807607137,
      "grad_norm": 0.2691422402858734,
      "learning_rate": 3.403676364162687e-06,
      "loss": 0.1309,
      "step": 22800
    },
    {
      "epoch": 1.9842820546220312,
      "grad_norm": 1.046929121017456,
      "learning_rate": 3.389202489506441e-06,
      "loss": 0.128,
      "step": 22850
    },
    {
      "epoch": 1.9886240284833485,
      "grad_norm": 9.4624662399292,
      "learning_rate": 3.3747286148501957e-06,
      "loss": 0.1663,
      "step": 22900
    },
    {
      "epoch": 1.9929660023446658,
      "grad_norm": 3.3540661334991455,
      "learning_rate": 3.36025474019395e-06,
      "loss": 0.094,
      "step": 22950
    },
    {
      "epoch": 1.9973079762059833,
      "grad_norm": 7.1674675941467285,
      "learning_rate": 3.345780865537705e-06,
      "loss": 0.1405,
      "step": 23000
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.21683721244335175,
      "eval_runtime": 158.5988,
      "eval_samples_per_second": 64.54,
      "eval_steps_per_second": 16.135,
      "step": 23031
    }
  ],
  "logging_steps": 50,
  "max_steps": 34545,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5.317128283815936e+19,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
